死锁（互斥 不可剥夺 请求和保持 环形等待）

CAS ABA问题、循环时间长开销很大、只能保证一个共享变量的原子操作
JVM 字节码 汇编指令
volatile lock前缀含内存屏障的两个作用 可见性（ 1.缓存写回主存 2.总线嗅探缓存一致协议） 有序性（禁止指令重排） 

JMM JAVA内存模型
happens before八原则（）
happens-before原则定义如下：
1. 如果一个操作happens-before另一个操作，那么第一个操作的执行结果将对第二个操作可见，而且第一个操作的执行顺序排在第二个操作之前。 
2. 两个操作之间存在happens-before关系，并不意味着一定要按照happens-before原则制定的顺序来执行。
如果重排序之后的执行结果与按照happens-before关系来执行的结果一致，那么这种重排序并不非法。
下面是happens-before原则规则：
程序次序规则：一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作；
锁定规则：一个unLock操作先行发生于后面对同一个锁额lock操作；
volatile变量规则：对一个变量的写操作先行发生于后面对这个变量的读操作；
传递规则：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C；
线程启动规则：Thread对象的start()方法先行发生于此线程的每个一个动作；
线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生；
线程终结规则：线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值手段检测到线程已经终止执行；
对象终结规则：一个对象的初始化完成先行发生于他的finalize()方法的开始；

synchronized（对象头mark word，不可降级，无锁-偏向锁（记录线程ID默认无竞争，出现竞争升级）-轻量级锁（自旋消耗CPU 适用耗时短的同步块 自旋获取锁失败升级）-
重量级锁（出现竞争则阻塞 用户态到内核态耗时 适用耗时长的同步块））
自适应自旋 锁消除（逃逸分析 线程局部去掉锁） 锁粗化（如果一系列操作反复加锁解锁 锁扩大到序列外）

为什么用了synchronized还要用volatile,以及可能出现的指令重排序影响双重检查加锁（double-checked locking)的正确性?
具体来说就是synchronized虽然保证了原子性，但却没有保证指令重排序的正确性，
会出现A线程执行初始化，但可能因为构造函数里面的操作太多了，所以A线程的uniqueInstance实例还没有造出来，但已经被赋值了。
而B线程这时过来了，错以为uniqueInstance已经被实例化出来，一用才发现uniqueInstance尚未被初始化。
----------------------------------------------------------------------------------------------
synchronized是无法禁止指令重排和处理器优化的！！！为什么还说synchronized也提供了有序性保证呢？
Java程序中天然的有序性可以总结为一句话：如果在本线程内观察，所有操作都是天然有序的。如果在一个线程中观察另一个线程，所有操作都是无序的。
as-if-serial语义的意思指：不管怎么重排序（编译器和处理器为了提高并行度），单线程程序的执行结果都不能被改变。
编译器和处理器无论如何优化，都必须遵守as-if-serial语义。
as-if-serial语义保证了单线程中，指令重排是有一定的限制的，而只要编译器和处理器都遵守了这个语义，那么就可以认为单线程程序是按照顺序执行的。
当然，实际上还是有重排的，只不过我们无须关心这种重排的干扰。
所以呢，由于synchronized修饰的代码，同一时间只能被同一线程访问。那么也就是单线程执行的。所以，可以保证其有序性。（指单线程下的有序性！！！）

as-if-serial语义保证单线程内程序的执行结果不被改变，happens-before关系保证正确同 步的多线程程序的执行结果不被改变。

（CAS Unsafe类 ABA） 
Java无法直接访问底层操作系统，而是通过本地（native）方法来访问。
不过尽管如此，JVM还是开了一个后门，JDK中有一个类Unsafe，它提供了硬件级别的原子操作。
CAS操作是通过compareAndSwapXXX方法实现的
/**
* 比较obj的offset处内存位置中的值和期望的值，如果相同则更新。此更新是不可中断的。
* 
* @param obj 需要更新的对象
* @param offset obj中整型field的偏移量
* @param expect 希望field中存在的值
* @param update 如果期望值expect与field的当前值相同，设置filed的值为这个新值
* @return 如果field的值被更改返回true
*/
public native boolean compareAndSwapInt(Object obj, long offset, int expect, int update);
AtomicInteger
AtomicReference原子引用，提供一个对象来供原子读写，可确保在多线程下操作的是同一个对象，且是同步操作

比如说一个线程one从内存位置V中取出A，这时候另一个线程two也从内存中取出A，并且two进行了一些操作变成了B，
然后two又将V位置的数据变成A，这时候线程one进行CAS操作发现内存中仍然是A，然后one操作成功。
尽管线程one的CAS操作成功，但是不代表这个过程就是没有问题的。
如果链表的头在变化了两次后恢复了原值，但是不代表链表就没有变化。
因此前面提到的原子操作AtomicStampedReference/AtomicMarkableReference就很有用了。这允许一对变化的元素进行原子操作。
各种乐观锁的实现中通常都会用版本戳version来对记录或对象标记，避免并发操作带来的问题，
在Java中，AtomicStampedReference也实现了这个作用，它通过包装[E,Integer]的元组来对对象标记版本戳stamp，
从而避免ABA问题，例如下面的代码分别用AtomicInteger和AtomicStampedReference来对初始值为100的原子整型变量进行更新，
AtomicInteger会成功执行CAS操作，而加上版本戳的AtomicStampedReference对于ABA问题会执行CAS失败。
--------------------- 

单例模式：饿汉 懒汉（双重校验锁 静态内部类 枚举）
我们会发现基于类 初始化的方案的实现代码更简洁。但基于volatile的双重检查锁定的方案有一个额外的优势： 
除了可以对静态字段实现延迟初始化外，还可以对实例字段实现延迟初始化。

运行时非检查异常（空指针 数组越界 JVM处理） 非运行时检查异常（IO SQL 显示处理） 异常被处理或者上抛 线程停止

线程之间的通信机制有两种：共享内存和消息传递
在共享内存并发模型 里，同步是显式进行的。程序员必须显式指定某个方法或某段代码需要在线程之间互斥执行。 
在消息传递的并发模型里，由于消息的发送必须在消息的接收之前，因此同步是隐式进行的。
Java的并发采用的是共享内存模型，Java线程之间的通信总是隐式进行，整个通信过程对 程序员完全透明。
如果两个操作访问同一个变量，且这两个操作中有一个为写操作，此时这两个操作之间 就存在数据依赖性

在一些32位的处理器上，如果要求对64位数据的写操作具有原子性，会有比较大的开销。
为了照顾这种处理器，Java语言规范鼓励但不强求JVM对64位的long型变量和double型变量的 写操作具有原子性。
当JVM在这种处理器上运行时，可能会把一个64位long/double型变量的写 操作拆分为两个32位的写操作来执行。
这两个32位的写操作可能会被分配到不同的总线事务 中执行，此时对这个64位变量的写操作将不具有原子性。

编译器重排序以及处理器重排序，内存屏障（Load读 Store写组合四种）


（AQS）
AQS
AQS即是AbstractQueuedSynchronizer，一个用来构建锁和同步工具的框架，包括常用的ReentrantLock、CountDownLatch、Semaphore等。
AbstractQueuedSynchronizer是一个抽象类，
主要是维护了一个int类型的state属性和一个！！！非阻塞、先进先出的线程同步队列以及可能存在的多个等待队列；
其中state是用volatile修饰的，保证线程之间的可见性，
队列的入队和出队操作都是无锁操作，基于自旋锁（在队列里自旋，检查自己是否头节点）和CAS（如果是头节点，尝试CAS获取锁）实现；
另外AQS分为两种模式：独占模式（exclusive）和共享模式（shared），像ReentrantLock是基于独占模式模式实现的，CountDownLatch、CyclicBarrier等是基于共享模式。
锁是面向使用者的，它定义了使用者与锁交 互的接口（比如可以允许两个线程并行访问），隐藏了实现细节；
同步器面向的是锁的实现者， 它简化了锁的实现方式，屏蔽了同步状态管理、线程的排队、等待与唤醒等底层操作。
锁和同 步器很好地隔离了使用者和实现者所需关注的领域。
同步器的设计是基于模板方法模式的，也就是说，使用者需要继承同步器并重写指定的 方法，随后将同步器组合在自定义同步组件的实现中，
并调用同步器提供的模板方法，而这些 模板方法将会调用使用者重写的方法。
同步器提供的模板方法基本上分为3类：独占式获取与释放同步状态、共享式获取与释放 同步状态和查询同步队列中的等待线程情况。
？？？为什么同步器内置的等待、同步队列是非阻塞的？？？
同步器提供了一个基于CAS的设置尾节点的方法：compareAndSetTail(Node expect,Node update)，它需要传递当前线程“认为”的尾节点和当前节点，
只有设置成功后，当前节点才正式 与之前的尾节点建立关联。在enq(final Node node)方法中，同步器通过“死循环”来保证节点的正确添加，
在“死循 环”中只有通过CAS将节点设置成为尾节点之后，当前线程才能从该方法返回，否则，当前线 程不断地尝试设置。
可以看出，enq(final Node node)方法将并发添加节点的请求通过CAS变 得“串行化”了。

同步队列遵循FIFO，首节点是获取同步状态成功的节点，首节点的线程在释放同步状态 时，将会唤醒后继节点，而后继节点将会在获取同步状态成功时将自己设置为首节点

在Java 5之前，当一 个线程获取不到锁而被阻塞在synchronized之外时，对该线程进行中断操作，此时该线程的中 断标志位会被修改，
但线程依旧会阻塞在synchronized上，等待着获取锁。在Java 5中，同步器 提供了acquireInterruptibly(int arg)方法，
这个方法在等待获取同步状态时，如果当前线程被中 断，会立刻返回，并抛出InterruptedException。

超时获取同步状态过程可以被视作响应中断获取同步状态过程的“增强版”，该方法在自旋过程中，当节点的前驱节点为头节点时尝试获取同步状态，
如果获取成功 则从该方法返回，这个过程和独占式同步获取的过程类似，但是在同步状态获取失败的处理 上有所不同。
如果当前线程获取同步状态失败，则判断是否超时（nanosTimeout小于等于0表示 已经超时），如果没有超时，重新计算超时间隔nanosTimeout，
然后使当前线程等待 nanosTimeout纳秒（当已到设置的超时时间，该线程会从LockSupport.parkNanos(Object blocker,long nanos)方法返回）。
如果nanosTimeout小于等于spinForTimeoutThreshold（1000纳秒）时，将不会使该线程进行 超时等待，而是进入快速的自旋过程。
原因在于，非常短的超时等待无法做到十分精确，如果 这时再进行超时等待，相反会让nanosTimeout的超时从整体上表现得反而不精确。
因此，在超 时非常短的场景下，同步器会进入无条件的快速自旋。

如果在绝对时间上，先对锁进行获取的请求一定先 被满足，那么这个锁是公平的，反之，是不公平的。
公平的获取锁，也就是等待时间最长的线 程最优先获取锁，也可以说锁获取是顺序的。
nonfairTryAcquire(int acquires)方法，对于非公平锁，只要CAS设置 同步状态成功，则表示当前线程获取了锁，而公平锁则不同，
tryAcquire该方法与nonfairTryAcquire(int acquires)比较，唯一不同的位置为判断条件多了 hasQueuedPredecessors()方法，
即加入了同步队列中当前节点是否有前驱节点的判断，如果该 方法返回true，则表示有线程比当前线程更早地请求获取锁，
因此需要等待前驱线程获取并释 放锁之后才能继续获取锁。

非公平性锁可能使线程“饥饿”，为什么它又被设定成默认的实现呢？
公平性锁每次都是从同步队列中的 第一个节点获取到锁，而非公平性锁出现了一个线程连续获取锁的情况。当一 个线程请求锁时，
只要获取了同步状态即成功获取锁。在这个前提下，刚释放锁的线程再次获 取同步状态的几率会非常大，使得其他线程只能在同步队列中等待。
！公平性锁保证了锁的获取按照FIFO原则，而代价是进行大量的线程切换。
！非公平性锁虽 然可能造成线程“饥饿”，但极少的线程切换，保证了其更大的吞吐量。

想ReentrantLock中自定义同步器的实现，同步状态表示锁被一个线程重复获取的次数，
而读 写锁的自定义同步器需要在同步状态（一个整型变量）上维护多个读线程和一个写线程的状 态，使得该状态的设计成为读写锁实现的关键。 
如果在一个整型变量上维护多种状态，就一定需要“按位切割使用”这个变量，读写锁将 变量切分成了两个部分，高16位表示读，低16位表示写

节点的定义复用了同步器中节点 的定义，也就是说，同步队列和等待队列中节点类型都是同步器的静态内部类 AbstractQueuedSynchronizer.Node。
Condition拥有首尾节点的引用，而新增节点只需要将原有的尾节点nextWaiter 指向它，并且更新尾节点即可。
！！！上述节点引用更新的过程并没有使用CAS保证，原因在于调用 await()方法的线程必定是获取了锁的线程，也就是说该过程是由锁来保证线程安全的。
（类似必须在synchronized内部调用wait()方法）



ReentrantLock的实现依赖于Java同步器框架AbstractQueuedSynchronizer（本文简称之为 AQS）。
AQS使用一个整型的volatile变量（命名为state）来维护同步状态
每个锁关联一个线程持有者和一个计数器。当计数器为0时表示该锁没有被任何线程持有，那么任何线程都都可能获得该锁而调用相应方法。
当一个线程请求成功后，JVM会记下持有锁的线程，并将计数器计为1。此时其他线程请求该锁，则必须等待。
而该持有锁的线程如果再次请求这个锁，就可以再次拿到这个锁，同时计数器会递增。
当线程退出一个synchronized方法/块时，计数器会递减，如果计数器为0则释放该锁。

仔细分析concurrent包的源代码实现，会发现一个通用化的实现模式。 
首先，声明共享变量为volatile。 然后，使用CAS的原子条件更新来实现线程之间的同步。
 同时，配合以volatile的读/写和CAS所具有的volatile读和写的内存语义来实现线程之间的 通信。
 AQS，非阻塞数据结构和原子变量类（java.util.concurrent.atomic包中的类），这些concurrent 包中的基础类都是使用这种模式来实现的，
 而concurrent包中的高层类又是依赖于这些基础类 来实现的。

与前面介绍的锁和volatile相比，对final域的读和写更像是普通的变量访问
对于final域，编译器和处理器要遵守两个重排序规则。 
1）在构造函数内对一个final域的写入，与随后把这个被构造对象的引用赋值给一个引用 变量，这两个操作之间不能重排序。
2）初次读一个包含final域的对象的引用，与随后初次读这个final域，这两个操作之间不能 重排序。
写final域的重排序规则可以确保：在对象引用为任意线程可见之前，对象的final域已经被 正确初始化过了，而普通域不具有这个保障。
以上图为例，在读线程B“看到”对象引用obj时， 很可能obj对象还没有构造完成
（对普通域i的写操作被重排序到构造函数外，此时初始值1还 没有写入普通域i）。
为了修补这个漏洞，JSR-133专家组增强了final的语义。通过为final域增加写和读重排序 规则，
可以为Java程序员提供初始化安全保证：只要对象是正确构造的（被构造对象的引用在 构造函数中没有“逸出”this），
那么不需要使用同步（指lock和volatile的使用）就可以保证任意线程 都能看到这个final域在构造函数中被初始化之后的值。

一个线程在一个时刻只能运行在一个处理器核心上
线程6种状态（new初始化 start就绪 运行 等待 阻塞 终止）
！进入阻塞的情况（(一). 同步阻塞：运行(running)的线程在获取对象的synchronized同步锁时，
若该同步锁被别的线程占用，则JVM会把该线程放入锁池(lock pool)中。
（二）发出了I/O请求时，JVM会把该线程置为阻塞状态。I/O处理完毕时，线程重新转入可运行(runnable)状态。）
！进入等待的情况（(一). 运行(running)的线程执行o.wait()方法，JVM会把该线程放入等待队列(waitting queue)中。
(二).运行(running)的线程执行Thread.sleep(long ms)或t.join()方法
当sleep()状态超时、join()等待线程终止或者超时，回到就绪态。注意Thread.sleep进入的时超时等待，其他方法可选无限期等待和超时等待。
（三）.在 java.concurrent包中Lock接口的线程阻塞状态却是等待状态，
因为java.concurrent包中Lock接口对于阻塞的实现均使用了LockSupport类中的相关方法。）
LockSupport
锁池(lock pool)，锁池里面放的都是想争夺对象锁的线程，一个对象对应一个锁池。
锁池:假设线程A已经拥有了某个对象(注意:不是类)的锁，而其它的线程想要调用这个对象的某个synchronized方法(或者synchronized块)，
由于这些线程在进入对象的synchronized方法之前必须先获得该对象的锁的拥有权，但是该对象的锁目前正被线程A拥有，
所以这些线程就进入了该对象的锁池中。

等待队列相当于休息区（不参与竞争除非被唤醒,分为无限期等待和超时等待），调用wait()进入，notify()或者notifyAll()才出来，三个方法都是Object类中的方法.
等待队列(waitting queue):假设一个线程A调用了某个对象的wait()方法，线程A就会释放该对象的锁
(因为wait()方法必须出现在synchronized中，这样自然在执行wait()方法之前线程A就已经拥有了该对象的锁)，
同时线程A就进入到了该对象的等待队列中。
如果另外的一个线程调用了相同对象的notifyAll()方法，那么处于该对象的等待池中的线程就会全部进入该对象的锁池中，准备争夺锁的拥有权。
如果另外的一个线程调用了相同对象的notify()方法，那么仅仅有一个处于该对象的等待池中的线程(随机)会进入该对象的锁池.

一般锁池包含一个state状态计数，以及一个阻塞队列实现的同步队列
同步队列(sync queue)对应是否公平地竞争锁，非公平锁可以在锁可以获取时，不进入同步队列直接竞争
--------------------------------------------------

几个方法的比较
Thread.sleep(long millis)，一定是当前线程调用此方法，当前线程进入阻塞，但不释放对象锁，millis后线程自动苏醒进入可运行状态。作用：给其它线程执行机会的最佳方式。
Thread.yield()，一定是当前线程调用此方法，当前线程放弃获取的cpu时间片，由运行状态变会可运行状态，让OS再次选择线程。作用：让相同优先级的线程轮流执行，但并不保证一定会轮流执行。实际中无法保证yield()达到让步目的，因为让步的线程还有可能被线程调度程序再次选中。Thread.yield()不会导致阻塞。
t.join()/t.join(long millis)，当前线程里调用其它线程1的join方法，当前线程阻塞，但不释放对象锁，直到线程1执行完毕或者millis时间到，当前线程进入可运行状态。
obj.wait()，当前线程调用对象的wait()方法，当前线程释放对象锁，进入等待队列。依靠notify()/notifyAll()唤醒或者wait(long timeout)timeout时间到自动唤醒。
obj.notify()唤醒在此对象监视器上等待的单个线程，选择是任意性的。notifyAll()唤醒在此对象监视器上等待的所有线程。


泛型 编译期擦除 上界不存 下界不取？PECS（Producer Extends Consumer Super）原则，已经很好理解了
频繁往外读取内容的，适合用上界Extends
经常往里插入的，适合用下界Super

限定通配符总是包括自己
上界类型通配符：add方法受限
下界类型通配符：get方法受限
如果你想从一个数据类型里获取数据，使用 ? extends 通配符
如果你想把对象写入一个数据结构里，使用 ? super 通配符
如果你既想存，又想取，那就别用通配符
不能同时声明泛型通配符上界和下界

Objeat类九种方法（getClass toString equals hashcode wait notify notifyAll clone finalize ）
Java八种基本类型（byte1 short2 int4 long8 float4 double8 char2 boolean1）

哈希函数
1）直接定址法 
取关键字或者关键字的某个线性函数为Hash地址，即Hash(key)=a*key+b
2）除留余数法 
如果知道Hash表的最大长度为m，可以取不大于m的最大质数（素数）p，然后对关键字进行取余运算，Hash(key)=key%p。 
在这里p的选取非常关键，p选择的好的话，能够最大程度地减少冲突，p一般取不大于m的最大质数。

哈希冲突解决办法：
拉链法 数组加单链表实现（删除简单 装填因子小则冲突小但浪费空间）

开放定址法 循环数组实现 再散列法（删除不能直接置空 下一个元素依赖上一个元素 计算时间增加）
这个方法的基本思想是：当发生地址冲突时，按照某种方法继续探测哈希表中的其他存储单元，直到找到空位置为止。这个过程可用下式描述： 
H i ( key ) = ( H ( key )+ d i ) mod m ( i = 1,2,…… ， k ( k ≤ m – 1)) 
其中： H ( key ) 为关键字 key 的直接哈希地址， m 为哈希表的长度， di 为每次再探测时的地址增量。 
采用这种方法时，首先计算出元素的直接哈希地址 H ( key ) ，如果该存储单元已被其他元素占用，则继续查看地址为 H ( key ) + d 2 的存储单元，如此重复直至找到某个存储单元为空时，将关键字为 key 的数据元素存放到该单元。 
增量 d 可以有不同的取法，并根据其取法有不同的称呼： 
（ 1 ） d i ＝ 1 ， 2 ， 3 ， …… 线性探测再散列； 
（ 2 ） d i ＝ 1^2 ，－ 1^2 ， 2^2 ，－ 2^2 ， k^2， -k^2…… 二次探测再散列； 
（ 3 ） d i ＝ 伪随机序列 伪随机再散列； 
--------------------- 

CountDownLatch 和 join？
1.相比较于join方法，CountDownLatch的优势在于不需要等待线程死亡才释放，
可以在满足条件的地方调用countDown方法就可以让计数减一，相比较于join更灵活可控一些。
2.并且通过线程池启动任务时不方便直接在线程对象上调用thread.join()

CountDownLatch类是一个同步计数器,构造时传入int参数,该参数就是计数器的初始值，
每调用一次countDown()方法，计数器减1,计数器大于0 时，await()方法会阻塞程序继续执行
当计数减至0时触发特定的事件。利用这种特性，可以让主线程等待子线程的结束。
下面以一个！！！模拟运动员比赛的例子加以说明（第一个CountDownLatch保证起跑时间一致，第二个CountDownLatch保证所有运动员完成比赛结束）

下面对上面说的三个辅助类进行一个总结：

　　1）CountDownLatch和CyclicBarrier都能够实现线程之间的等待，只不过它们侧重点不同：

　　　　CountDownLatch一般用于某个线程A等待若干个其他线程执行完任务之后，它才执行；

　　　　而CyclicBarrier一般用于一组线程互相等待至某个状态，然后这一组线程再同时执行；

　　　　另外，CountDownLatch是不能够重用的，而CyclicBarrier是可以重用的。

　　2）Semaphore其实和锁有点类似，它一般用于控制对某组资源的访问权限。
-----------------------------------------------------------------------
手写生产者消费者
（“多个”生产消费者实例 
1.用阻塞队列实现（利用了ReentrantLock以及其中Condition的await/signalAll实现），核心思想是，把并发和容量控制封装在缓冲区中
2.用wait/notifyAll机制加锁（synchronized 相当于 semaphore值为1）实现（在Object提供的消息通知机制应该遵循如下这些条件：
永远在while循环中对条件进行判断而不是if语句中进行wait条件的判断，循环会在线程“睡眠前后都检查”wait的条件；

Thread.interrupted()会清掉中断标志位，需要配合线程自己中断自己，在有while的地方除了判断业务条件，都要判断Thread.currentThread().isInterrupted()，否则会出现中断不被处理的情况
catch (InterruptedException e) {
                    System.out.println(Thread.currentThread().isInterrupted());
                }
捕获中断异常也会清理中断标志位，清理后需要考虑避免无法退出线程

shutdown() will just tell the executor service that it can't accept new tasks, 
but the already submitted tasks continue to run
shutdownNow() will do the same AND will try to cancel the already submitted tasks by interrupting the relevant threads. 
Note that if your tasks ignore the interruption, shutdownNow will behave exactly the same way as shutdown.
优雅的关闭，用shutdown()
想立马关闭，并得到未执行任务列表，用shutdownNow()
优雅的关闭，并允许关闭声明后新任务能提交，用awaitTermination()
关闭功能 【从强到弱】 依次是：shuntdownNow() > shutdown() > awaitTermination()
使用NotifyAll而不是使用notify，可能出现生产者唤醒生产者，消费者唤醒消费者，假死。） 
3.使用ReentrantLock以及其中Condition的await/signalAll实现）（优点实现full和empty两个condition，可以分情况唤醒消费者生产者
以此让优化消费者与消费者（或生产者与生产者）之间是串行的；消费者与生产者之间是并行的。）
生产者生产的时候消费者不能消费，消费者消费的时候生产者不能生产，缓冲区空时消费者不能消费，缓冲区满时生产者不能生产
生产者/模型作为一种重要的模型，它的优点在于：
1解耦。因为多了一个缓冲区，所以生产者和消费者并不直接相互调用，这一点很容易想到，这样生产者和消费者的代码发生变化，
都不会对对方产生影响，这样其实就把生产者和消费者之间的强耦合解开，变为了生产者和缓冲区/消费者和缓冲区之间的弱耦合
2通过平衡生产者和消费者的处理能力来提高整体处理数据的速度，这是生产者/消费者模型最重要的一个优点。
如果消费者直接从生产者这里拿数据，如果生产者生产的速度很慢，但消费者消费的速度很快，那消费者就得占用CPU的时间片白白等在那边。

Condition类
Condition是Java提供来实现等待/通知的类，Condition类还提供比wait/notify更丰富的功能，Condition对象是由lock对象所创建的。
！！！但是同一个锁可以创建多个Condition的对象，即创建多个对象监视器（一个对象监视器对应一个等待队列）。这样的好处就是可以指定唤醒线程。
Condition 将 Object 监视器方法（wait、notify 和 notifyAll）分解成截然不同的对象，以便通过将这些对象与任意 Lock 实现组合使用，为每个对象提供多个等待 set （wait-set）。
其中，Lock 替代了 synchronized 方法和语句的使用，Condition 替代了 Object 监视器方法的使用。
在Condition中，用await()替换wait()，用signal()替换notify()，用signalAll()替换notifyAll()，
传统线程的通信方式，Condition都可以实现，这里注意，Condition是被绑定到Lock上的，要创建一个Lock的Condition必须用newCondition()方法。
Condition与Object中的wait, notify, notifyAll区别
1.Condition中的await()方法相当于Object的wait()方法，Condition中的signal()方法相当于Object的notify()方法，
Condition中的signalAll()相当于Object的notifyAll()方法。
不同的是，Object中的这些方法是和同步锁捆绑使用的；而Condition是需要与互斥锁/共享锁捆绑使用的。
2.Condition它更强大的地方在于：能够更加精细的控制多线程的休眠与唤醒。
对于同一个锁，我们可以创建多个Condition，在不同的情况下使用不同的Condition。
例如，假如多线程读/写同一个缓冲区：当向缓冲区中写入数据之后，唤醒”读线程”；当从缓冲区读出数据之后，唤醒”写线程”；
并且当缓冲区满的时候，”写线程”需要等待；当缓冲区为空时，”读线程”需要等待。
如果采用Object类中的wait(),notify(),notifyAll()实现该缓冲区，当向缓冲区写入数据之后需要唤醒”读线程”时，
不可能通过notify()或notifyAll()明确的指定唤醒”读线程”，而只能通过notifyAll唤醒所有线程(但是notifyAll无法区分唤醒的线程是读线程，
还是写线程)。 但是，通过Condition，就能明确的指定唤醒读线程。

阻塞队列/java/util/concurrent/BlockingQueue.java的实现 fair ConditionObject()
1.BlockingQueue定义的常用方法如下:

 	抛出异常	特殊值	阻塞	超时
插入	add(e)	offer(e)	put(e)	offer(e, time, unit)
移除	remove()	poll()	take()	poll(time, unit)
检查	element()	peek()	不可用	不可用


        1)add(anObject):把anObject加到BlockingQueue里,即如果BlockingQueue可以容纳,则返回true,否则招聘异常

        2)offer(anObject):表示如果可能的话,将anObject加到BlockingQueue里,即如果BlockingQueue可以容纳,则返回true,否则返回false.

        3)put(anObject):把anObject加到BlockingQueue里,如果BlockQueue没有空间,则调用此方法的线程被阻断直到BlockingQueue里面有空间再继续.

        4)poll(time):取走BlockingQueue里排在首位的对象,若不能立即取出,则可以等time参数规定的时间,取不到时返回null

        5)take():取走BlockingQueue里排在首位的对象,若BlockingQueue为空,阻断进入等待状态直到Blocking有新的对象被加入为止

其中：BlockingQueue 不接受null元素。试图add、put 或offer 一个null 元素时，某些实现会抛出NullPointerException。
null被用作指示poll操作失败的警戒值！！！
BlockingQueue 可以是限定容量的。它在任意给定时间都可以有一个remainingCapacity，超出此容量，便无法无阻塞地put附加元素。
没有任何内部容量约束的BlockingQueue 总是报告Integer.MAX_VALUE 的剩余容量。

阻塞队列（有界队列）常用三种实现（存在共性：与有限maximumPoolSizes一起使用时有助于防止资源耗尽，但可能更难以调整和控制。 
队列大小和最大池大小可以相互交换：使用大型队列和小型池最小化CPU使用率，OS资源和上下文切换开销，但可能导致人为的低吞吐量。 
如果任务经常阻塞（例如，如果它们是I / O绑定的），系统可能能够为您提供比您允许的更多线程的时间。 
使用小队列通常需要更大的池大小，这会使CPU更加繁忙，但可能会遇到不可接受的调度开销，这也会降低吞吐量。
put take 操作都是阻塞的
offer poll 操作不是阻塞的，offer 队列满了会返回false不会阻塞，poll 队列为空时会返回null不会阻塞
有界队列是一种特殊的队列，当队列为空时，队列的获取操作 将会阻塞获取线程，直到队列中有新增元素，
当队列已满时，队列的插入操作将会阻塞插入线 程，直到队列出现“空位”）
ArrayBlockingQueue、LinkedBlockingQueue、SynchronousQueue
1)ArrayBlockingQueue:由数组支持的有界阻塞队列，规定大小的BlockingQueue,
其构造函数必须带一个int参数来指明其大小.其所含的对象是以FIFO(先入先出)顺序排序的.
在创建ArrayBlockingQueue的时候默认创建的是非公平锁（fair=false），不过我们可以在它的构造函数里指定。
这里调用ReentrantLock的构造函数创建锁的时候，调用了：
public ReentrantLock(boolean fair) {

sync = (fair)? new FairSync() : new NonfairSync();

}
FairSync/ NonfairSync是ReentrantLock的内部类：
线程按顺序请求获得公平锁，而一个非公平锁可以闯入，且当它尚未进入等待队列，就会和等待队列head结点的线程发生竞争，
如果锁的状态可用，请求非公平锁的线程可在等待队列中向前跳跃，获得该锁。内部锁synchronized没有提供确定的公平性保证。
ArrayBlockingQueue 实现简单，表现稳定，添加和删除使用同一个锁，通常性能不如后者LinkedBlockingQueue
2)LinkedBlockingQueue:大小不定的BlockingQueue,若其构造函数带一个规定大小的参数,生成的BlockingQueue有大小限制,
若不带大小参数,所生成的BlockingQueue的大小由Integer.MAX_VALUE来决定.（optionally-bounded，bounded ou unbounded）
其所含的对象是以FIFO(先入先出)顺序排序的
LinkedBlockingQueue 添加和删除两把锁是分开的，所以竞争会小一些
3)SynchronousQueue:特殊的BlockingQueue,对其的操作必须是放和取交替完成的。每一个put操作必须等待一个take操作， 否则不能继续添加元素。
内部容量为零，适用于元素数量少的场景，队列本身并不存储任何元素，非常适合传递性场景。
负责把生产者线程处理的数据直接传递给消费者线程。
内部使用 队列来实现公平性的调度，使用栈来实现非公平的调度

阻塞队列（无界队列）常用四种实现（无界队列的共同点：maximumPoolSize起不到作用
put 操作永远都不会阻塞，空间限制来源于系统资源的限制，底层都使用CAS无锁编程）
1)PriorityBlockingQueue:类似于LinkedBlockQueue,但其所含对象的排序不是FIFO,
而是依据传入的构造函数的Comparator（compare()方法）决定的顺序，或者是对象的自然排序顺序（实现Comparable接口compareTo()方法）
2）ConcurrentLinkedQueue 无锁队列，底层使用CAS操作，通常具有较高吞吐量，但是具有读性能的不确定性，
弱一致性——不存在如ArrayList等集合类的并发修改异常，通俗的说就是遍历时修改不会抛异常
3）DelayedQueue 延时队列，使用场景 
缓存：清掉缓存中超时的缓存数据
任务超时处理
补充：内部实现其实是采用带时间的优先队列，可重入锁，优化阻塞通知的线程元素leader
4）LinkedTransferQueue 简单的说也是进行线程间数据交换的利器，在SynchronousQueue 中就有所体现
-----------------------------------------------------------------
deque双端队列
SynchronousQueue
DelayQueue、BlockingDeque、LinkedBlockingDeque

---------------------------------------------------------------------------
线程池（四种 具体参数（核心池 使用的阻塞队列 最大池 非核心池存活时间） 适用场景 
keepAliveTime 线程池中超过corePoolSize数目的空闲线程最大存活时间 可以设置核心池也回收
线程池的工作线程空闲后，保持存活的时间。所以， 如果任务很多，并且每个任务执行的时间比较短，可以调大时间，提高线程的利用率。
keepAliveTime when the number of threads is greater than
     *        the core, this is the maximum time that excess idle threads
     *        will wait for new tasks before terminating.
线程池5种状态转移（running shutdown(shutdown) stop(shutdownNow) tyding terminated）
只要调用了这两个关闭方法中的任意一个，isShutdown方法就会返回true。
当所有的任务 都已关闭后，才表示线程池关闭成功，这时调用isTerminaed方法会返回true。
至于应该调用哪 一种方法来关闭线程池，应该由提交到线程池的任务特性决定，通常调用shutdown方法来关闭 线程池，如果任务不一定要执行完，则可以调用shutdownNow方法。
对比线程（初始化 就绪 运行 阻塞 等待 终结）
优点重复利用资源避免反复创建对象垃圾回收，解耦线程任务结果）
ScheduledThreadPoolExecutor继承了ThreadPoolExecutor类，因此，整体上功能一致，
线程池主要负责创建线程（Worker类），线程从阻塞队列中不断获取新的异步任务，直到阻塞队列中已经没有了异步任务为止。
但是相较于ThreadPoolExecutor来说，ScheduledThreadPoolExecutor具有延时执行任务和可周期性执行任务的特性，
ScheduledThreadPoolExecutor重新设计了任务类ScheduleFutureTask,
ScheduleFutureTask重写了run方法使其具有可延时执行和可周期性执行任务的特性。
另外，阻塞队列DelayedWorkQueue是可根据优先级排序的队列，采用了堆的底层数据结构，使得与当前时间相比，待执行时间越靠近的任务放置队头，以便线程能够获取到任务进行执行；

public ScheduledThreadPoolExecutor(int corePoolSize) {
        super(corePoolSize, Integer.MAX_VALUE,
              DEFAULT_KEEPALIVE_MILLIS, MILLISECONDS,
              new DelayedWorkQueue());
    }

public static ExecutorService newFixedThreadPool(int nThreads) {
        return new ThreadPoolExecutor(nThreads, nThreads,
                                      0L, TimeUnit.MILLISECONDS,
                                      new LinkedBlockingQueue<Runnable>());
    }	

public static ExecutorService newSingleThreadExecutor() {
        return new FinalizableDelegatedExecutorService
            (new ThreadPoolExecutor(1, 1,
                                    0L, TimeUnit.MILLISECONDS,
                                    new LinkedBlockingQueue<Runnable>()));
    }
	
public static ExecutorService newCachedThreadPool() {
        return new ThreadPoolExecutor(0, Integer.MAX_VALUE,
                                      60L, TimeUnit.SECONDS,
                                      new SynchronousQueue<Runnable>());
    }
------------------------
ThreadPoolExecutor的判断
if (corePoolSize < 0 ||
            maximumPoolSize <= 0 ||
            maximumPoolSize < corePoolSize ||
            keepAliveTime < 0)
            throw new IllegalArgumentException();
-----------------------
线程池无论是ThreadPoolExecutor还是ScheduledThreadPoolExecutor，在设计时的三个关键要素是：任务，执行者以及任务结果。
它们的设计思想也是完全将这三个关键要素进行了解耦。

如果调用了线程池的prestartAllCoreThreads()方法， 线程池会提前创建并启动所有基本线程。
RejectedExecutionHandler（饱和策略）：当队列和线程池都满了，说明线程池处于饱和状 态，那么必须采取一种策略处理提交的新任务。
这个策略默认情况下是AbortPolicy，表示无法 处理新任务时抛出异常。在JDK 1.5中Java线程池框架提供了以下4种策略。 
·AbortPolicy：直接抛出异常。 ·CallerRunsPolicy：只用调用者所在线程来运行任务。 ·
DiscardOldestPolicy：丢弃队列里最近的一个任务，并执行当前任务。 ·DiscardPolicy：不处理，丢弃掉。 
当然，也可以根据应用场景需要来实现RejectedExecutionHandler接口自定义策略。如记录 日志或持久化存储不能处理的任务。
defaultHandler默认是new AbortPolicy()

要想合理地配置线程池，就必须首先分析任务特性，可以从以下几个角度来分析。 ·任务的性质：CPU密集型任务、IO密集型任务和混合型任务。 
·任务的优先级：高、中和低。 ·任务的执行时间：长、中和短。 ·任务的依赖性：是否依赖其他系统资源，如数据库连接。 
性质不同的任务可以用不同规模的线程池分开处理。CPU密集型任务应配置尽可能小的 线程，如配置Ncpu+1个线程的线程池。
由于IO密集型任务线程并不是一直在执行任务，则应配 置尽可能多的线程，如2*Ncpu。
混合型的任务，如果可以拆分，将其拆分成一个CPU密集型任务 和一个IO密集型任务，只要这两个任务执行的时间相差不是太大，
那么分解后执行的吞吐量 将高于串行执行的吞吐量。如果这两个任务执行时间相差太大，则没必要进行分解。
可以通过 Runtime.getRuntime().availableProcessors()方法获得当前设备的CPU个数。 
优先级不同的任务可以使用优先级队列PriorityBlockingQueue来处理。它可以让优先级高 的任务先执行。
依赖数据库连接池的任务，因为线程提交SQL后需要等待数据库返回结果，等待的时间越长，则CPU空闲时间就越长，
那么线程数应该设置得越大，这样才能更好地利用CPU。

建议使用有界队列。有界队列能增加系统的稳定性和预警能力，可以根据需要设大一点 儿，比如几千。
有一次，我们系统里后台任务线程池的队列和线程池全满了，不断抛出抛弃任 务的异常，
通过排查发现是数据库出现了问题，导致执行SQL变得非常缓慢，因为后台任务线 程池里的任务全是需要向数据库查询和插入数据的，
所以导致线程池里的工作线程全部阻 塞，任务积压在线程池里。
如果当时我们设置成无界队列，那么线程池的队列就会越来越多， 有可能会撑满内存，导致整个系统不可用，而不只是后台任务出现问题。
当然，我们的系统所 有的任务是用单独的服务器部署的，我们使用不同规模的线程池完成不同类型的任务，但是出现这样问题时也会影响到其他任务。

Executor框架主要由3大部分组成如下。
·任务。包括被执行任务需要实现的接口：Runnable接口（run()方法）或Callable接口（call()方法）。 
·任务的执行。包括任务执行机制的核心接口Executor，以及继承自Executor的 ExecutorService接口。
Executor框架有两个关键类实现了ExecutorService接口：
（ThreadPoolExecutor（继承自AbstractExecutorService） 和 ScheduledThreadPoolExecutor）。 
·异步计算的结果。包括接口Future和实现Future接口的FutureTask类。
由于FutureTask实现了Runnable，因此FutureTask既是Future、Runnable，
又包装了Callable( 如果构造函数传入Runnable最终也会被转换为Callable )，它是这两者的合体。

（Runnable可以提交给Thread.start()直接启动一个线程来执行或ExecuteService.execute()，
也可以和result（null）包装成Callable，在ExecuteService.submit()里重载
而Callable则一般都是提交给ExecuteService.submit()来执行）
线程池的execute或者submit流程：
主线程首先要创建实现Runnable或者Callable接口的任务对象。
execute“无返回值”1可以把Runnable对象直接交给ExecutorService执行（ExecutorService.execute（Runnable command）
submit“有返回值”2工具类Executors.callable()方法可以把一个Runnable对象封装为一个Callable对象：
Executors.callable（Runnable task）传入Runnable（+null）或 Executors.callable（Runnable task，Object resule）传入Runnable + result。 
或者也可以把Runnable对象或Callable对象提交给ExecutorService执行：
Executor- Service.submit（Runnable task）或ExecutorService.submit（Callable<T>task））。 
如果执行ExecutorService.submit（…），ExecutorService将返回一个实现Future接口的对象 （到目前为止的JDK中，返回的是FutureTask对象）。
程序员也可以创建FutureTask，然后直接交给ExecutorService执行。 
最后，主线程可以执行FutureTask.get()方法来等待任务执行完成，阻塞或者超时返回。主线程也可以执行
FutureTask.cancel（boolean mayInterruptIfRunning）来取消此任务的执行。


用的是工具类Executors.callable()方法把runnable包装成callable：
public static <T> Callable<T> callable(Runnable task, T result) {
        if (task == null)
            throw new NullPointerException();
        return new RunnableAdapter<T>(task, result);
    }
public static Callable<Object> callable(Runnable task) {
        if (task == null)
            throw new NullPointerException();
        return new RunnableAdapter<Object>(task, null);
    }
用到适配器模式（在callable的call()方法里调用runnable的run()方法，并返回给定值）：
**
     * A callable that runs given task and returns given result.
     */
    private static final class RunnableAdapter<T> implements Callable<T> {
        private final Runnable task;
        private final T result;
        RunnableAdapter(Runnable task, T result) {
            this.task = task;
            this.result = result;
        }
        public T call() {
            task.run();
            return result;
        }
        public String toString() {
            return super.toString() + "[Wrapped task = " + task + "]";
        }
    }


线程内的异常处理：1try catch 2通过FutureTask处理


并发总结
https://www.weiweiblog.cn/thread/
进程间的通信方式
管道( pipe )：管道是一种半双工的通信方式，数据只能单向流动，而且只能在具有亲缘关系的进程间使用。进程的亲缘关系通常是指父子进程关系。
有名管道 (namedpipe) ： 有名管道也是半双工的通信方式，但是它允许无亲缘关系进程间的通信。
信号量(semophore ) ： 信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。
消息队列( messagequeue ) ： 消息队列是由消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。
共享内存(shared memory ) ：共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的 IPC 方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号两，配合使用，来实现进程间的同步和通信。
套接字(socket ) ： 套解口也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同主机及其间的进程通信。
线程间的通信方式
锁机制：包括互斥锁、条件变量、读写锁
 互斥锁提供了以排他方式防止数据结构被并发修改的方法。
 读写锁允许多个线程同时读共享数据，而对写操作是互斥的。
 条件变量可以以原子的方式阻塞进程，直到某个特定条件为真为止。对条件的测试是在互斥锁的保护下进行的。条件变量始终与互斥锁一起使用。
信号量机制(Semaphore)：包括无名线程信号量和命名线程信号量
共享内存
线程间的通信目的主要是用于线程同步。

到了JDK1.6，synchronize加入了很多优化措施，有自适应自旋，锁消除，锁粗化，轻量级锁，偏向锁等等。
导致在JDK1.6上synchronize的性能并不比Lock差。官方也表示，他们也更支持synchronize，在未来的版本中还有优化余地，
所以还是提倡在synchronized能实现需求的情况下，优先考虑使用synchronized来进行同步。
锁的状态
Java SE1.6为了减少获得锁和释放锁所带来的性能消耗，引入了“偏向锁”和“轻量级锁”，
所以在Java SE1.6里锁一共有四种状态，无锁状态，偏向锁状态，轻量级锁状态和重量级锁状态，它会随着竞争情况逐渐升级。
锁可以升级但不能降级，意味着偏向锁升级成轻量级锁后不能降级成偏向锁。这种锁升级却不能降级的策略，目的是为了提高获得锁和释放锁的效率。

偏向锁
在没有实际竞争的情况下，还能够针对部分场景继续优化。如果不仅仅没有实际竞争，自始至终，使用锁的线程都只有一个，
那么，维护轻量级锁都是浪费的。偏向锁的目标是，减少无竞争且只有一个线程使用锁的情况下，使用轻量级锁产生的性能消耗。轻量级锁每次申请、释放锁都至少需要一次CAS，但偏向锁只有初始化时需要一次CAS。
“偏向”的意思是，偏向锁假定将来只有第一个申请锁的线程会使用锁（不会有任何线程再来申请锁），
因此，只需要在Mark Word中CAS记录owner（本质上也是更新，但初始值为空），如果记录成功，则偏向锁获取成功，
记录锁状态为偏向锁，以后当前线程等于owner就可以零成本的直接获得锁；否则，说明有其他线程竞争，膨胀为轻量级锁。
偏向锁无法使用自旋锁优化，因为一旦有其他线程申请锁，就破坏了偏向锁的假定。
轻量级锁
轻量级锁是由偏向所升级来的，偏向锁运行在一个线程进入同步块的情况下，当第二个线程加入锁争用的时候，偏向锁就会升级为轻量级锁。
轻量级锁是在没有多线程竞争的前提下，减少传统的重量级锁使用产生的性能消耗。
轻量级锁所适应的场景是线程交替执行同步块的情况，如果存在同一时间访问同一锁的情况，就会导致轻量级锁膨胀为重量级锁。
使用轻量级锁时，不需要申请互斥量，仅仅将Mark Word中的部分字节CAS更新指向线程栈中的Lock Record，如果更新成功，则轻量级锁获取成功，
记录锁状态为轻量级锁；否则，说明已经有线程获得了轻量级锁，目前发生了锁竞争（不适合继续使用轻量级锁），接下来膨胀为重量级锁。
重量级锁
重量锁在JVM中又叫对象监视器（Monitor），它很像C中的Mutex，除了具备Mutex(0|1)互斥的功能，它还负责实现了Semaphore(信号量)的功能，
也就是说它至少包含一个竞争锁的队列，和一个信号阻塞队列（wait队列），前者负责做互斥，后一个用于做线程同步。
自旋锁
自旋锁原理非常简单，如果持有锁的线程能在很短时间内释放锁资源，
那么那些等待竞争锁的线程就不需要做内核态和用户态之间的切换进入阻塞挂起状态，它们只需要等一等（自旋），
等持有锁的线程释放锁后即可立即获取锁，这样就避免用户线程和内核的切换的消耗。
但是线程自旋是需要消耗cup的，说白了就是让cup在做无用功，如果一直获取不到锁，那线程也不能一直占用cup自旋做无用功，
所以需要设定一个自旋等待的最大时间。
如果持有锁的线程执行的时间超过自旋等待的最大时间扔没有释放锁，就会导致其它争用锁的线程在最大等待时间内还是获取不到锁，
这时争用线程会停止自旋进入阻塞状态。
自适应自旋锁
自适应意味着自旋的时间不再固定了，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定：
如果在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也很有可能再次成功，
进而它将允许自旋等待持续相对更长的时间，比如100个循环。
相反的，如果对于某个锁，自旋很少成功获得过，那在以后要获取这个锁时将可能减少自旋时间甚至省略自旋过程，以避免浪费处理器资源。
自适应自旋解决的是“锁竞争时间不确定”的问题。JVM很难感知到确切的锁竞争时间，而交给用户分析就违反了JVM的设计初衷。
自适应自旋假定不同线程持有同一个锁对象的时间基本相当，竞争程度趋于稳定，因此，可以根据上一次自旋的时间与结果调整下一次自旋的时间。

偏向锁、轻量级锁、重量级锁适用于不同的并发场景
偏向锁：无实际竞争，且将来只有第一个申请锁的线程会使用锁。
轻量级锁：无实际竞争，多个线程交替使用锁；允许短时间的锁竞争。
重量级锁：有实际竞争，且锁竞争时间长。
另外，如果锁竞争时间短，可以使用自旋锁进一步优化轻量级锁、重量级锁的性能，减少线程切换。
如果锁竞争程度逐渐提高（缓慢），那么从偏向锁逐步膨胀到重量锁，能够提高系统的整体性能。

锁膨胀的过程：只有一个线程进入临界区（偏向锁），多个线程交替进入临界区（轻量级锁），多线程同时进入临界区并自旋获取锁失败（重量级锁）。


public abstract void run();
V call() throws Exception;
1call方法可以抛出检查异常，run方法不可以。
2Callable的任务执行后可返回值，而Runnable的任务是不能返回值的。
运行Callable任务可以拿到一个Future对象，表示异步计算的结果。
3Callable提供了检查计算是否完成的方法，以等待计算的完成，并检索计算的结果。
通过Future对象可以了解任务执行情况，可取消任务的执行，还可获取执行结果。
A* {@code Runnable}, however, does not return a result and cannot
 * throw a checked exception.
三种submit方法，有两种可以让Runnable在完成时返回给定的null或者result

Future就是对于具体的Runnable或者Callable任务的执行结果进行取消、查询是否完成、获取结果。
必要时可以通过get方法获取执行结果，该方法会阻塞直到任务返回结果。
FutureTask使用？？？以及处理异常
也就是说Future提供了三种功能：
　　1）判断任务是否完成；
　　2）能够中断任务；
　　3）能够获取任务执行结果。
　　因为Future只是一个接口，所以是无法直接用来创建对象使用的，因此就有了下面的FutureTask。

setDaemon(true)：设置为后台线程。
后台线程主要是为其他线程（相对可以称之为前台线程）提供服务，或“守护线程”。
如JVM中的垃圾回收线程。当所有的前台线程都进入死亡状态时，后台线程会自动死亡。
这意味着，当一个Java虚拟机中不存在非Daemon线程的时候，Java虚拟机将会退出。
注意 Daemon属性需要在启动线程之前设置，不能在启动线程之后设置。 
Daemon线程被用作完成支持性工作，！！！但是在Java虚拟机退出时Daemon线程中的finally块 并不一定会执行

/java/util/concurrent/locks/ReentrantLock.java
（优点：可以实现公平锁非公平锁，默认非公平；可以读写锁分开；粒度更细，可以分多个Condition进行await()signalAll()
tryLock()可以尝试获取锁，lockInterruptibly()可以响应中断;
缺点finally手动解锁）
1lock(), 拿不到lock就不罢休，不然线程就一直block。 比较无赖的做法。
2tryLock()，马上返回，拿到lock就返回true，不然返回false。 比较潇洒的做法。
带时间限制的 tryLock(long timeout,
                       @NotNull java.util.concurrent.TimeUnit unit)，拿不到lock，就等一段时间，超时返回false。等待的时间也会响应中断，比较聪明的做法。
3下面的lockInterruptibly()就稍微难理解一些。
先说说线程的打扰机制，每个线程都有一个 打扰 标志。这里分两种情况，
1. 线程在sleep或wait,join， 此时如果别的进程调用此进程的 interrupt（）方法，
此线程会被唤醒并被要求处理InterruptedException；(thread在做IO操作时也可能有类似行为，见java thread api)
2. 此线程在运行中， 则不会收到提醒。但是 此线程的 “打扰标志”会被设置， 可以通过isInterrupted()查看并 作出处理。
lockInterruptibly()和上面的第一种情况是一样的， 线程在请求lock并被阻塞时，
如果被interrupt，则“此线程会被唤醒并被要求处理InterruptedException”。

ReadWriteLock
不过要注意的是，如果有一个线程已经占用了读锁，则此时其他线程如果要申请写锁，则申请写锁的线程会一直等待释放读锁。
如果有一个线程已经占用了写锁，则此时其他线程如果申请写锁或者读锁，则申请的线程会一直等待释放写锁。

lock为什么不放在try里？
不要将获取锁的过程写在try块中，因为如果在获取锁（自定义锁的实现）时发生了异常，异常抛出的同时，也会导致锁无故释放
（因为还未获取到锁，抛出异常最后执行finally，没有获取到锁进行unlock又会抛出java.lang.IllegalMonitorStateException）。

jps查看当前用户下的java进程的pid及基本信息 
jstack使用jstack可查看指定进程（pid）的堆栈信息，用以分析线程情况： 
NEW：未启动的。不会出现在Dump中。 
RUNNABLE：在虚拟机内执行的。 
BLOCKED：受阻塞并等待监视器锁。 
WATING：无限期等待另一个线程执行特定操作。 
TIMED_WATING：有时限的等待另一个线程的特定操作。 
TERMINATED：已退出的。
首先通过使用jps -l获得pid，再通过jmap -heap pid查看堆内存配置及使用情况： 
---------------------------------
？？？
1用户态内核态为什么切换（为了内核数据安全，用户修改内核数据需要从用户态切换为内核态，
避免高特权（比如 内核态）栈内存被低特权（比如 用户态）任意修改。
比如内核态的特征是cpu可以访问内存的所有数据，包括外围设备），
2什么时候切换（！！！当线程进行切换的时候，由用户态转化为内核态。切换完毕要从内核态返回用户态。
！！！这个切换耗时，所以考虑尽量减少。
！！！多任务运行一定会进行切换，为了协作进入等待状态（主动）也会切换，所以就需要减少因为进入加锁阻塞状态（被动）的切换次数！！！）
3为什么耗时（上下文切换，CPU记录并恢复不同线程，使它能够完成切换操作。
每个线程都有一个程序计数器（记录要执行的下一条指令），一组寄存器（保存当前线程的工作变量），
堆栈（记录执行历史，其中每一帧保存了一个已经调用但未返回的过程））
4用户态切换到内核态的3种方式
a. 系统调用
这是用户态进程主动要求切换到内核态的一种方式，用户态进程通过系统调用申请使用操作系统提供的服务程序完成工作，
比如前例中fork()实际上就是执行了一个创建新进程的系统调用。而系统调用的机制其核心还是使用了操作系统为用户特别开放的一个中断来实现，
例如Linux的int 80h中断。
b. 异常
当CPU在执行运行在用户态下的程序时，发生了某些事先不可知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关程序中，
也就转到了内核态，比如缺页异常。
c. 外围设备的中断
当外围设备完成用户请求的操作后，会向CPU发出相应的中断信号，
这时CPU会暂停执行下一条即将要执行的指令转而去执行与中断信号对应的处理程序，如果先前执行的指令是用户态下的程序，
那么这个转换的过程自然也就发生了由用户态到内核态的切换。比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等。

这3种方式是系统在运行时由用户态转到内核态的最主要方式，其中系统调用可以认为是用户进程主动发起的，异常和外围设备中断则是被动的。

！！！final除了类不能继承、方法不能重写、基本类型值不变、引用类型指向不变，还有写先于读的内存语义：
直接赋值或者在构造函数内赋值
在旧的Java内存模型中，一个最严重的缺陷就是线程可能看到final域的值会改变。
比如， 一个线程当前看到一个整型final域的值为0（还未初始化之前的默认值，是无效值），过一段时间之后这个 线程再去读这个final域的值时，
却发现值变为1（被某个线程初始化之后的值）。最常见的例子 就是在旧的Java内存模型中，String的值可能会改变。 
为了修补这个漏洞，JSR-133专家组增强了final的语义。通过为final域增加写和读重排序 规则，
可以为Java程序员提供初始化安全保证：只要对象是正确构造的（被构造对象的引用在 构造函数中没有“逸出”），
那么不需要使用同步（指lock和volatile的使用）就可以保证任意线程 都能看到这个final域在构造函数中被初始化之后的值。

如果该 线程已经处于终结状态，即使该线程被中断过，在调用该线程对象的isInterrupted()时依旧会返 回false。 
从Java的API中可以看到，许多声明抛出InterruptedException的方法（例如Thread.sleep(long millis)方法）这些方法在抛出InterruptedException之前，Java虚拟机会先将该线程的中断标识位 清除，
然后抛出InterruptedException，此时调用isInterrupted()方法将会返回false

中断状态是线程的一个标识位，而中断操作是一种简便的线程间交互 方式，而这种交互方式最适合用来取消或停止任务。
除了中断以外，还可以利用一个boolean变 量来控制是否需要停止任务并终止该线程。
通过标识位或者中断操作的方式能够使线程在终止时有机会去清理资源，而不是武断地 将线程停止，
因此这种终止线程的做法显得更加安全和优雅。

notify()或notifyAll()方法调用后，等待线程依旧不会从wait()返回，
需要调用notify()或 notifAll()的线程释放锁之后，等待线程才有机会从wait()返回。

管道输入/输出流和普通的文件输入/输出流或者网络输入/输出流不同之处在于，它主要 用于线程之间的数据传输，而传输的媒介为内存。 
管道输入/输出流主要包括了如下4种具体实现：PipedOutputStream、PipedInputStream、 PipedReader和PipedWriter，
前两种面向字节，而后两种面向字符。

中Thread.join()方法的源码，调用了所等待线程的wait()，当线程终止时，会调用线程自身的notifyAll()方法，
会通知所有等待在该线程对象上的线程。
------------------------------------------------------------------------
笔试时经常会出现的一个问题，float型float f=3.4是否正确 
答案：不正确。 
原因：精度不准确,应该用强制类型转换，如下所示：float f=(float)3.4 或float f = 3.4f 
在java里面，没小数点的默认是int,有小数点的默认是 double; 
编译器可以自动向上转型，如int 转成 long 系统自动转换没有问题，因为后者精度更高 
double 转成 float 就不能自动做了，所以后面的加上个 f;

Map map = new HashMap<>();
            map.keySet();
            map.entrySet();
            map.values();
因为value可以重复

阿里巴巴代码规范检查插件（
判断相等对象最好放在equals调用方，避免报null异常
创建hashmap如果知道大小，最好事先指定2的n次方，因为rehash耗时
线程不直接new Thread(),采用线程池，并且显示传参创建）


数组加链表（优化后链表过长可转换红黑树）
！！！1HashMap在并发执行put操作，引起扩容时，可能因为多线程导致HashMap的Entry链表形成环形数据结构，
Entry的next节点永远不为空，当在数组该位置get寻找对应的key时，就发生了死循环，引起CPU的100%问题。
查看get()和getNode()方法
/**
     * Returns the value to which the specified key is mapped,
     * or {@code null} if this map contains no mapping for the key.
     *
     * <p>More formally, if this map contains a mapping from a key
     * {@code k} to a value {@code v} such that {@code (key==null ? k==null :
     * key.equals(k))}, then this method returns {@code v}; otherwise
     * it returns {@code null}.  (There can be at most one such mapping.)
     *
     * <p>A return value of {@code null} does not <i>necessarily</i>
     * indicate that the map contains no mapping for the key; it's also
     * possible that the map explicitly maps the key to {@code null}.
     * The {@link #containsKey containsKey} operation may be used to
     * distinguish these two cases.
     *
     * @see #put(Object, Object)
     */
    public V get(Object key) {
        Node<K,V> e;
        return (e = getNode(hash(key), key)) == null ? null : e.value;
    }
返回null可能key为null，或者存的值就是null。

/**
     * Implements Map.get and related methods.
     *
     * @param hash hash for key
     * @param key the key
     * @return the node, or null if none
     */
    final Node<K,V> getNode(int hash, Object key) {
        Node<K,V>[] tab; Node<K,V> first, e; int n; K k;
        if ((tab = table) != null && (n = tab.length) > 0 &&
            (first = tab[(n - 1) & hash]) != null) {
            if (first.hash == hash && // always check first node
                ((k = first.key) == key || (key != null && key.equals(k))))
                return first;
            if ((e = first.next) != null) {
                if (first instanceof TreeNode)
                    return ((TreeNode<K,V>)first).getTreeNode(hash, key);
                do {
                    if (e.hash == hash &&
                        ((k = e.key) == key || (key != null && key.equals(k))))
                        return e;
                } while ((e = e.next) != null);
            }
        }
        return null;
    }
首先判断第一个节点，
！！！判断相等的过程(与条件false不继续，或条件true不继续)：
哈希值不相等肯定不等，不继续判断（这样效率高）===>哈希值相等判断引用地址是否相等（这里是引用类型）===>最后用equals()，没重写Object默认用==
！！！（为什么重写equals()就一定要重写hashcode()？？？
因为Map查找先判断hashcode()，不重写就会出现hashcode判断不等，但equals()相等的情况
默认相同的对象必须有相同的哈希值，但相同的哈希值不一定是相同的对象）。
后面继续查找节点，根据first instanceof TreeNode判断是否红黑树，否则链表查找。
进入链表查找do {} while ((e = e.next) != null); 这里可能出现死循环。

2HashMap使用一个Entry数组保存key、value数据，当一对key、value被加入时，会通过一个hash算法得到数组的下标index，
算法很简单，根据key的hash值，对数组的大小取模 hash & (length-1)，并把结果插入数组该位置，
如果该位置上已经有元素了，就说明存在hash冲突，这样会在index位置生成链表。
如果存在hash冲突，最惨的情况，就是所有元素都定位到同一个位置，形成一个长长的链表，
这样get一个值时，最坏情况需要遍历所有节点，性能变成了O(n)，所以元素的hash值算法和HashMap的初始化大小很重要。
当put时，如果存在相同的key，则替换并且返回旧值，否则先会判断当前内部元素是否已经达到阈值threshold（默认是数组大小的0.75，
0.75为负载因子，负载因子越小，冲突几率越小），如果已经达到阈值，会对数组进行扩容，也会对链表中的元素进行rehash。
DEFAULT_INITIAL_CAPACITY = 1 << 4; // aka 16默认容量
DEFAULT_LOAD_FACTOR = 0.75f;负载因子
MAXIMUM_CAPACITY = 1 << 30;最大容量

3扩容或初始化过程：
resize()
Initializes or doubles table size. using power-of-two expansion, the
elements from each bin must either stay at same index, or move
with a power of two offset in the new table.经过rehash之后，元素的位置要么是在原位置，要么是在原位置再移动2次幂的位置。
时机：大于等于阈值并且当前发送冲突
新数组大小为目前的两倍，所有元素重新计算哈希值，头插法插入链表（避免每次插入遍历到尾部耗时）
	 

4int表值范围从-2147483648到2147483648。前后加起来大概40亿的映射空间。
static final int hash(Object key) {
        int h;
        return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
    }
！！！key.hashCode()把自身高低位通过异或操作混合，叫做扰动函数，掺杂高位特征，增加低位的随机性。
！！！而且看到key == null时哈希值直接取0，证明可以存放一个null key，并且是放在数组index=0处，
所以get(null)返回对应存的值。如果key不存在或者存的值就是null，都返回null。需要通过containsKey()区分。
！！！为什么容量MUST be a power of two.必须是2的次方？
（2的n次方减一正好得到一个低位掩码，通过和哈希值低位与操作求出应该放的数组下标
掩码是一串二进制代码对目标字段进行位与运算，屏蔽当前的部分输入位。）
put过程调用其它方法有这两行（通过与操作求出应该放的数组下标）
n = tab.length；
index = (n - 1) & hash]；



使用线程安全的HashTable效率又非常低下
HashTable容器使用synchronized来保证线程安全，同一时间只允许一个线程访问，独占模式



双数组加链表（优化后链表过长可转换红黑树），分段锁技术
/java/util/concurrent/ConcurrentHashMap.java（共享模式）
ConcurrentHashMap是由Segment数组结构和HashEntry数组结构组成。
分段锁继承ReentrantLock，在ConcurrentHashMap里扮演锁的角色；HashEntry则用于存储键值对数据。
一个ConcurrentHashMap里包含一个Segment数组。Segment的结构和HashMap类似，是一种数组和链表结构。
一个Segment里包含一个HashEntry数组，每个HashEntry是一个链表结构的元素，
每个Segment守护着一个HashEntry数组里的元素，当对HashEntry数组的数据进行修改时， 必须首先获得与它对应的Segment锁
当一个线程占用锁访问其中一个段数据的时候，其他段的数 据也能被其他线程访问。
构造函数包含initialCapacity、loadFactor、concurrencyLevel 
concurrencyLevel the estimated number of concurrently
     * updating threads. The implementation may use this value as
     * a sizing hint.
segments数组的长度ssize是通过concurrencyLevel计算得出的。为了能通过按位与的散列算法来定位segments数组的索引，
必须保证segments数组的长度是2的N次方 ，所以必须计算出一个大于或等于concurrencyLevel的最小的2的N次方值来作为segments数组的长度。
假如concurrencyLevel等于14、15或16，ssize都会等于16，即容器里 锁的个数也是16。
注意 concurrencyLevel的最大值是65535，这意味着segments数组的长度最大为65536，对应的二进制是16位。
并发度可以理解为程序运行时能够同时更新ConccurentHashMap且不产生锁竞争的最大线程数，实际上就是ConcurrentHashMap中的分段锁个数，
即Segment[]的数组长度。ConcurrentHashMap默认的并发度为16，但用户也可以在构造函数中设置并发度。
当用户设置并发度时，ConcurrentHashMap会使用大于等于该值的最小2幂指数作为实际并发度（假如用户设置并发度为17，实际并发度则为32）。
运行时通过将key的高n位（n = 32 – segmentShift）和并发度减1（segmentMask）做位与运算定位到所在的Segment。
segmentShift与segmentMask都是在构造过程中根据concurrency level被相应的计算出来。
如果并发度设置的过小，会带来严重的锁竞争问题；如果并发度设置的过大，原本位于同一个Segment内的访问会扩散到不同的Segment中，
CPU cache命中率会下降，从而引起程序性能下降。

再散列，目的是减少散列冲突，使元素能够均匀地分布在不同的Segment上， 从而提高容器的存取效率。
假如散列的质量差到极点，那么所有的元素都在一个Segment中， 不仅存取元素缓慢，分段锁也会失去意义。

Segment的get操作实现非常简单和高效。先经过一次再散列，然后使用这个散列值通过散 列运算定位到Segment，再通过散列算法定位到元素，
代码如下。 public V get(Object key) { int hash = hash(key.hashCode()); return segmentFor(hash).get(key, hash); } 
get操作的高效之处在于整个get过程不需要加锁，除非读到的值是空才会加锁重读。
我们 知道HashTable容器的get方法是需要加锁的，那么ConcurrentHashMap的get操作是如何做到不 加锁的呢？
原因是它的get方法里将要使用的共享变量都定义成volatile类型，如用于统计当前 Segement大小的count字段和用于存储值的HashEntry的value。
定义成volatile的变量，能够在线 程之间保持可见性，能够被多线程同时读，并且保证不会读到过期的值，
但是只能被单线程写 （有一种情况可以被多线程写，就是写入的值不依赖于原值），
在get操作里只需要读不需要写 共享变量count和value，所以可以不用加锁。
之所以不会读到过期的值，是因为根据Java内存模 型的happen before原则，对volatile字段的写入操作先于读操作，
即使两个线程同时修改和获取 volatile变量，get操作也能拿到最新的值，这是用volatile替换锁的经典应用场景。 
transient volatile int count; volatile V value; 
在定位元素的代码里我们可以发现，定位HashEntry和定位Segment的散列算法虽然一样， 都与数组的长度减去1再相“与”，但是相“与”的值不一样，
定位Segment使用的是元素的 hashcode通过再散列后得到的值的高位，而定位HashEntry直接使用的是再散列后的值。其目的
是避免两次散列后的值一样，虽然元素在Segment里散列开了，但是却没有在HashEntry里散列 开。
hash >>> segmentShift) & segmentMask // 定位Segment所使用的hash算法 int index = hash & (tab.length - 1); // 定位HashEntry所使用的hash算法

！！！为什么ConcurrentHashMap不支持null key value？？？
** Implementation for put and putIfAbsent */
    final V putVal(K key, V value, boolean onlyIfAbsent) {
        if (key == null || value == null) throw new NullPointerException();
		....}
In a non-concurrent map, you can check this via map.contains(key), 
but in a concurrent one, the map might have changed between calls. 
non-concurrent可以调用map.contains(key)检查，
当ConcurrentMaps使用map.get(key)时返回为null,无法区分key是没映射不存在 还是 映射值为null，
因为ConcurrentMaps可能在两次调用间已经发生改变！！！所以压根就不让put null。

！！！弱一致性
1get与containsKey两个方法几乎完全一致：他们都没有使用锁，而是通过Unsafe对象的getObjectVolatile()方法提供的原子读语义，
来获得Segment以及对应的链表，然后对链表遍历判断是否存在key相同的节点以及获得该节点的value。
但由于遍历过程中其他线程可能对链表结构做了调整，因此get和containsKey返回的可能是过时的数据，
这一点是ConcurrentHashMap在弱一致性上的体现。如果要求强一致性，那么必须使用Collections.synchronizedMap()方法。

2整个get过程不需要加锁，除非读到的值是空才会加锁重读。

！！！更新
ConcurrentHashMap在JDK8中进行了巨大改动，它摒弃了Segment（锁段）的概念，而是启用了一种全新的方式实现,利用CAS算法。
它沿用了与它同时期的HashMap版本的思想，底层依然由“数组”+链表+红黑树的方式思想(JDK7与JDK8中HashMap的实现)，
但是为了做到并发，又增加了很多辅助的类，例如TreeBin，Traverser等对象内部类。

原子类：原子更新基本类型，原子更新数组，原子更新引用类型，原子更新字段类



集群（aaa负载均衡） 分布式(abc 业务分离) 微服务(进程隔离 http调用 SpringCloud框架，微服务全家桶) 
HTTP的Rest API 对外
rpc对内(dubble、grpc,rmi建立在协议之上 是一种框架 针对服务治理 简化协议更高效 序列化反序列化获取对象)
RPC：主要用在自家系统之间的互相调用，即实现系统的分布式。 
mq使微服务异步 
进程通信（管道 消息队列 共享内存 信号量 socket（不同机器 套接字 抽象tcp/ip协议））
