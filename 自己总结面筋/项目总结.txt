-----------------------------------------------
模型托管平台
-----------------------------------------------
2生产者消费者模式，lock 针对executeId的condition await（timeout） signal机制

3
一、执行模型的线程池设计：由于每个任务互相独立单独起线程，不需要进入阻塞队列。
采用cachedThreadPool，60秒会回收，核心池0最大池Integer.MAX_VALUE，默认AbortPolicy用不上，SynchronousQueue
外部根据事先设置的变量控制并发度，参考计算节点的性能。
getActiveCount()查看达到并发度时拒绝执行，避免MAX_POOLSIZE=Integer.MAX_VALUE引起的资源耗尽。
二、同步数据脚本文件的线程池设计：从obs下大文件耗时，线程数较多适合IO密集 
cachedThreadPool，60秒会回收，核心池0最大池Integer.MAX_VALUE，默认AbortPolicy用不上，SynchronousQueue
固定大小10 getActiveCount()查看达到并发度时拒绝执行

4controller 也可以使用拦截器
AOP（反射 动态代理），@Aspect定义日志切面类，切入时机用到before和after,再定义切点为模型调用的controller，
打印日志（HttpServletRequest getRequestURL()获取请求地址；joinPoint.getArgs()获取调用模型的参数等）、
加入ThreadLocal执行耗时计算（
如果不set默认的initialValue()返回null，可以在before时set()当前系统时间，也可以重写initialValue()，在before时get()一下。
最后在after时用最新时间减去get()值得到。
）

5项目索引怎么建的？（说执行表、日志表）
每次调用生成唯一的executeId,作为执行表主键，
日志表每行对应一条日志，logId自增，因为日志查询大多针对一次调用（executeId）查询出对应连续行的日志，
适合聚集索引，但只是executeId不能保证唯一性，所以在（executeId,logId）上建立组合索引的主键。
mysql> CREATE TABLE log(
    -> log_id INT NOT NULL AUTO_INCREMENT COMMENT '日志ID',
    -> execute_id INT NOT NULL COMMENT '执行ID',
	-> log VARCHAR(1000) NOT NULL COMMENT '日志记录',
    -> status CHAR(1) NOT NULL COMMENT 'D DEBUG I INFO W WARN E ERROR',
	-> create_time DATE COMMENT '生成时间',
    -> PRIMARY KEY (execute_id,log_id) 
    -> )ENGINE=InnoDB DEFAULT CHARSET=utf8;
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
curator 
每个Server（包括leader和fowller）在内存中存储了一份数据,需要在 宕机！，网络延时！等情况下保持一致性。
zab/raft协议
1leader选举（Zookeeper 启动时 或者 之前leader挂掉   （leader --candidate--follower ））
定时器超时后作为candidate 求票超过一半成为leader 是否存活通过保持心跳（监听同理）
leader宕机或者因网络延迟丢失心跳重新选举 
2主从复制
相当于23pc 由leader作为协调者接收写请求 follwer作为参与者 如果超过一半写成功返回成功
！！！
1zookeeper 
四种节点类型：
PERSIST，
持久节点 不会因为创建该节点的客户端会话失效而消失。
PERSIST_SEQUENTIAL,
在ZK中，每个 父节点 会为他的 第一级子节点 维护一份时序，会记录每个子节点创建的先后顺序。
那么在创建节点过程中，ZK会 自动 为给定节点名加上一个数字后缀，作为新的节点名。这个数字后缀的范围是整型的最大值。 
在创建节点的时候只需要传入节点 “/test_”，这样之后，zookeeper自动会给”test_”后面补充数字。
EPHEMERAL,
和持久节点不同的是，临时节点的生命周期和客户端会话绑定！
这里提到的是会话失效，而非连接断开！！！另外，在临时节点下面不能创建子节点。 
EPHEMERAL_SEQUENTIAL

！分布式锁 ：临时+顺序节点 序列号最前获得锁 其他Watch它前面的一个，避免重复通知、避免羊群效应
利用数据库实现分布式锁，几个字段：需要加锁的方法，当前持有者，计数实现可重入，超时时间避免锁无法释放
对要加锁的方法建立唯一索引，获取锁就是插入记录过程，成功插入获取锁。否则while循环里插入

每个客户端往/exlusive_lock下创建有序临时节点/exlusive_lock/lock_。
创建成功后/exlusive_lock下面会有每个客户端对应的节点，如/exlusive_lock/lock_000000001（zk父节点下自动递增）
客户端getChildren(“exlusive_lock”)方法取得/exlusive_lock下子节点，并进行排序，判断排在最前面的是否为自己。
如果自己的锁节点在第一位，代表获取锁成功，此客户端执行业务逻辑
如果自己的锁节点不在第一位，则监听自己前一位的锁节点。例如，自己锁节点lock_000000002，那么则监听lock_000000001.
当前一位锁节点（lock_000000001）对应的客户端执行完成，主动释放了锁！，或者会话超时导致临时节点被删，被动释放锁
将会触发监听客户端（lock_000000002）的逻辑。监听客户端重新执行第2步逻辑，判断自己是否获得了锁。
如此修改后，每个客户端只关心自己前序锁是否释放，所以每次只会有一个客户端得到通知。
而且，所有客户端的执行顺序和最初锁创建的顺序是一致的。
避免了如下两个问题：
1、锁的获取顺序和最初客户端争抢顺序不一致，这不是一个公平锁。每次锁获取都是当次最先抢到锁的客户端。
2、羊群效应，所有没有抢到锁的客户端都会监听/exlusive_lock变更。当并发客户端很多的情况下，所有的客户端都会接到通知去争抢锁，
此时就出现了羊群效应。

要想准确的拿到分布式锁，并且准确的捕获在分布式情况下锁的动态转移状态，需要处理网络变化带来的连锁反应。
比如常见的 session expire、connectionLoss，在设置lock状态的时候我们如何保证准确拿到lock。
在设计任务的时候我们需要具有 stop point 的策略，这个策略是用来在感知到lock丢失后能够交付执行权的机制。

！节点监控（钩子的局限性）：临时节点，Watch机制，通过和客户端保持心跳来监控 客户端下线临时节点删除
临时节点有一个特点：当创建临时节点的程序停掉之后，这个临时节点就会消失。
监视器的特点：可以给zk中的节点注册监视器，监视这个节点的变化情况。
监视器注册一次，只能使用一次，多次使用就要多次注册。
我们利用这个Zookeeper的临时节点特性+监视器(Watch)来实现分布式集群监控
首先计算节点均在/monitor（永久节点）下创建临时节点，mgmt监视monitor节点,获取下面的所有子节点的变化情况

！文件同步：永久节点 通过redo日志保证持久性



zookeeper java api的操作以及返回类型
创建会话
Zookeeper(String connectString,int sessionTimeout,Watcher watcher,long sessionId,byte[] sessionPasswd,boolean canBeReadOnly)
参数说明： 
1. connectString ： host:port[，host:port]指定的服务器列表，多个host:port之间用英文逗号分隔。
还可以可选择的指定一个基路径，如果指定了一个基路径，则所有后续操作基于这个及路径进行。
例如：188.12.23.25:2181,59.23.22.25:2181 像 [ip:端口号]这样的形式 
！！！2. sessionTimeOut – 会话超时时间。以毫秒为单位。
客户端和服务器端之间的连接通过心跳包进行维系，如果心跳包超过这个指定时间则认为会话超时失效。
一般设置为private static final int SESSION_TIMEOUT = 30000;？？？ 
3. watcher – 指定默认观察者。如果为null表示不需要观察者。 
4. canBeReadOnly – 是否支持只读服务。只当一个服务器失去过半连接后不能再进行写入操作时，是否继续支持读取操作。略 
5. sessionId、SessionPassword – 会话编号 会话密码，用来实现会话恢复。
返回类型：上述返回的是一个zookeeper对象 ZooKeeper zk = new ZooKeeper(hosts, zktest.SESSION_TIMEOUT, this.wh);
**注意，整个创建会话的过程是异步的，构造方法会在初始化连接后即返回，并不代表真正建立好了一个会话，此时会话处于”CONNECTING”状态。 
**当会话真正创建起来后，服务器会发送事件通知给客户端，只有客户端获取到这个通知后，会话才真正建立。
————————————————
心跳机制（leader follower（zk集群） |客户端（模型托管平台））
Zookeeper判断一个节点死亡down掉了，唯一一个可靠的途径就是心跳。
如leader和follower保持心跳证明自己存活，也是使用心跳来判断客户端是否仍然活着。



建立连接、会话：
！客户端首次连接其中一台zk节点=》生成会话整个集群保存+全局唯一Session ID=》会话开始计时=》保持心跳则重置会话超时时间
在ZooKeeper中，客户端和服务端建立连接后，会话随之建立，生成一个全局唯一的会话ID(Session ID)。
服务器和客户端之间维持的是一个长连接，在SESSION_TIMEOUT时间内，
服务器会确定客户端是否正常连接(客户端会定时向服务器发送heart_beat，服务器！重置！下次SESSION_TIMEOUT时间)。
因此，在正常情况下，Session一直有效，！并且ZK集群所有机器上都保存这个Session信息！。

！！！三类异常：连接断开、会话超时、会话过期
连接断开是什么？
connectionTimeoutMs ConnectionLoss 链接丢失
网络的不稳定 或是 客户端、及所连接的服务器宕机的时候，导致客户端和某个zk节点的连接断开。
这个时候客户端会 自动 在！地址列表！（实例化ZK对象的时候传入构造方法的那个参数connectString）中选择新的地址进行连接。
！超过连接超时时间——>ZK客户端捕获“连接断开”异常 ——> 从connectString获取一个新的ZK地址 ——> 尝试连接

获取链接的超时时间？
连接断开后会自动尝试重新获取连接

会话超时是什么？会话过期什么区别？
sessionTimeoutMs 会话超时 SessionExpired 会话过期
通常是ZK客户端与服务器的连接断了，试图连接上新的ZK机器，但是这个过程如果耗时过长，
超过了SESSION_TIMEOUT 后还没有成功连接上服务器，那么服务器认为这个Session已经结束了
（服务器无法确认是因为网络闪断 还是 客户端主动结束会话），
由于在ZK中，很多数据和状态都是和会话绑定的，一旦会话失效，那么ZK就开始清除这个会话创建的临时节点和注册的所有Watcher。
在这之后，如果由于网络恢复，客户端可能会重新连接上服务器，但是很不幸，服务器会告诉客户端一个异常：SESSIONEXPIRED（会话过期）。
此时客户端的状态变成 CLOSED状态，要重新实例zookeeper对象，然后重新操作所有临时数据（包括临时节点和注册Watcher）。
！尝试连接超过会话超时时间——>ZK结束会话 清除临时节点和注册的所有Watcher——> 
——>如果之前是网络闪断 客户端重新连上 告知会话过期
——>如果之前是客户端主动结束的 重新建立会话

多久临时节点会消失？sessionTimeoutMs 会话超时时间设置？
超过了会话超时时间 临时节点会消失
客户端并不是可以随意设置这个会话超时时间，在ZK服务器端对会话超时时间是有限制的，
主要是minSessionTimeout和maxSessionTimeout这两个参数设置的。
（如果客户端设置的超时时间不在这个范围，那么会被强制设置为最大或最小时间。 
默认的Session超时时间是在2 * tickTime ~ 20 * tickTime。）

配置ZooKeeper
tickTime单位为微秒，时间单位定量，用于session注册 和 客户端和ZooKeeper服务的心跳周期。
session超时时长 单位毫秒默认30000毫秒 最小为 tickTime的2倍 最大20倍（session超时接收不到心跳 代表客户端或者leader 宕机 网络延时 
后者还是存活的 考虑网络延时的影响 所以会话超时最小为心跳周期的两倍 设置上限避免会话无法超时）
dataDir ZooKeeper的状态存储位置，看名字就知道是数据目录。在你的系统中检查这个目录是否存在，如果不存在手动创建，并且给予可写权限。
clientPort 客户端连接的端口。不同的服务器可以设置不同的监听端口，！默认是2181


！！！假死、脑裂是什么？zk如何避免？（过半节点投票！）
1如果leader因分区网络问题丢失部分心跳 但没有宕机 称假死（网络延时不稳定 但没有宕机）
2网络造成分区出现假死 将选举出现新的leader 和之前leader同时服务造成分区不一致性 称脑裂（分区 多个leader）
3zk要求票数超过集群总数的一半才能成为leader，所以同时只可能存在一个leader，
因为也只有在可用节点过半时，集群才能选举，才是可用的。

！！！假死，旧的leader复活并且仍然认为自己是leader怎么办？（epoch机制！）
网络延时或者不稳定造成的分区不可能完全避免，引入epoch机制，随着每一任leader递增，
followers如果确认了新的leader存在，知道其epoch，就会拒绝epoch小于现任leader epoch的所有请求
这个时候旧leader向其他followers发出写请求也是会被拒绝的，（得不到大多数支持的写是无效的）
旧leader发现自己的epoch小于当前epoch，自动恢复成follower，并和新leader保持一致。

zk集群个数你们几台？容错多少？
3台，一半投票数3/2=1，即至少需要2台，容错为1允许一台宕机，保持集群可用。

为什么设置奇数（根据要求票数过半分析）？
1。奇数和它后面的一个偶数容错一样，故为了节省资源设置奇数台。
比如3台，3/2=1，只允许1台宕机
然后4台，4/2=2，也只允许1台宕机
2。分区为2时，偶数集群将会存在不可用的情况
比如3台，1，2分区是可用的
然后4台，1，3分区是可用的，但是2，2分区不可用


https://www.cnblogs.com/wangiqngpei557/p/10323149.html
绕开 zookeeper broker 进行状态通知
做好幂等
静态扩容、动态扩容
分布式架构理论raft zabZookeeper Atomic Broadcast(Zookeeper原子广播）/paxos
Zab协议是为分布式协调服务Zookeeper专门设计的一种 ！支持崩溃恢复！（redo undo日志） 的 原子广播协议 ，
是Zookeeper保证数据一致性的核心算法。Zab借鉴了Paxos算法，但又不像Paxos那样，是一种通用的分布式一致性算法。
基于该协议，zk实现了一种主备模型（即Leader和Follower模型）的系统架构来保证集群中各个副本之间数据的一致性。
这里的主备系统架构模型，就是指只有一台客户端（Leader）负责处理外部的写事务请求，然后Leader客户端将数据同步到其他Follower节点。
Zookeeper 客户端会随机的链接到 zookeeper 集群中的一个节点，如果是读请求，就直接从当前节点中读取数据；
如果是写请求，那么节点就会向 Leader 提交事务，Leader 接收到事务提交，会广播该事务，只要超过半数节点写入成功，该事务就会被提交。
--------------------- 
acid事务
a原子性提交或者回滚、c一致性比如A给B转账，事务中间的值对外不可见，不能出现A转了还没到B的情况、
i隔离性四种隔离级别对应解决脏读 不可重复读 幻读、d持久性事务提交后就算节点崩溃也不会丢失通过redo重做日志
分布式了解过吗？
拜占庭将军 网络延迟闪断 宕机等情况下，保持分布式各个节点的一致性（弱一致性最终一致 可用性）

CAP/BASE理论？
在一个分布式系统中，Consistency（一致性）、 Availability（可用性）、Partition tolerance（分区容错性），
最多只能同时三个特性中的两个，三者不可兼得。（比如保持强一致性，leader写就需要对其他follower加锁，那么存在不可用的情况）
Consistency (一致性)：针对节点间的数据一致！
即更新操作成功并返回客户端后，所有节点在同一时间的数据完全一致，这就是分布式的一致性
Availability (可用性):针对写的时候某个读请求正常响应！
即服务一直可用，任意时间请求任意可用的节点都是正常响应
Partition Tolerance (分区容错性):针对整个系统允许一定程度宕机！
即分布式系统在遇到某节点或网络分区故障的时候，仍然能够对外提供满足一致性或可用性的服务。
比如现在的分布式系统中有某一个或者几个机器宕掉了，其他剩下的机器还能够正常运转满足系统需求，对于用户而言并没有什么体验上的影响。


CAP三个特性只能满足其中两个，那么取舍的策略就共有三种：
CA without P：如果不要求P（不允许分区），则C（强一致性）和A（可用性）是可以保证的。
但放弃P的同时也就意味着放弃了系统的扩展性，也就是分布式节点受限，没办法部署子节点，
这是违背分布式系统设计的初衷的，分布式就是要在节点宕机时 具有一定容错能力。
节点故障、网络故障是常态，因此分区容错性也就成为了一个分布式系统必然要面对的问题。那么就只能在C和A之间进行取舍。
故P一定要满足。
CP without A： ！例如银行转账的业务（必须保持数据一致 宁愿牺牲可用性）！
如果不要求A（可用），相当于每个请求都需要在服务器之间保持强一致，
而P（分区）会导致同步时间无限延长(也就是等待数据同步完才能正常访问服务)，一旦发生网络故障或者消息丢失等情况，
就要牺牲用户的体验，等待所有数据全部一致了之后再让用户访问系统。
设计成CP的系统其实不少，最典型的就是分布式数据库，如Redis、HBase等。对于这些分布式数据库来说，
数据的一致性是最基本的要求，因为如果连这个标准都达不到，那么直接采用关系型数据库就好，没必要再浪费资源来部署分布式数据库。
AP wihtout C：！例如抢购商品的服务！（保持可用性可以点击 在不一致时提示抢购失败）
要高可用并允许分区，则需放弃一致性。一旦分区发生，节点之间可能会失去联系，
为了高可用，每个节点只能用本地数据提供服务，而这样会导致全局数据的不一致性。
典型的应用就如某米的抢购手机场景，可能前几秒你浏览商品的时候页面提示是有库存的，
当你选择完商品准备下单的时候，系统提示你下单失败，商品已售完。
这其实就是先在 A（可用性）方面保证系统可以正常的服务，然后在数据的一致性方面做了些牺牲，
虽然多少会影响一些用户体验，但也不至于造成用户购物流程的严重阻塞。
————————————————
base理论在ca中做妥协 弱一致性 最终一致 基本可用
BASE：全称：Basically Available(基本可用)，Soft state（软状态）,
和 Eventually consistent（最终一致性）三个短语的缩写，来自 ebay 的架构师提出。
软状态指的是：允许系统中的数据存在中间状态，并认为该状态不影响系统的整体可用性，
即允许系统在多个不同节点的数据副本存在数据延时。

分布式事务
！2pc 两阶段提交 Two-Phase Commit（协调者 参与者；协调者发起事务请求 统计收到的事务执行结果 决策提交或者回滚
参与者收到请求就直接开始执行事务了 回滚可以在中间收到no时回滚 提交必须全部回复yes
核心是对每个事务都采用先尝试后提交的处理方式！）
阶段一:发起事务请求(又称为投票阶段)    
1.事务询问    协调者向所有的参与者发送事务内容,询问是否可以进行执行事务提交操作.并开始等待各参与者的响应.    
2.执行事务    各个参与者节点执行事务操作,并讲Undo和Redo信息记入事务日志中.    
3.各参与者向协调者反馈事务询问的响应.   如果参与者成功执行了事务操作,那么就反馈给协调者Yes响应,表示事务可以执行,
如果没有参与者成功执行事务,那么就反馈给协调者No响应,表示事务不可以执行. 
阶段二:执行事务提交    
在阶段二中,协调者会根据各参与者的反馈情况来决定最终是否可以进行事务提交操作,正常情况下有两种可能:    
可能性一:执行成功(条件:所有参与者给协调者的信息都是YES)
1.所有的参与者反馈给协调者的信息都是Yes,那么就会执行事务提交.        协调者向所有参与者节点发出Commit请求.    
2.事务提交        参与者收到Commit请求之后,就会正式执行事务提交操作,并在完成提交之后释放整个事务执行期间占用的事务资源.    
3.反馈事务提交的结果        参与者在完成事务提交之后,向协调者发送ACK消息.    
4. 完成事务        协调者接收所有参与者反馈的Ack消息,完成事务.    
可能性二:执行失败,中断事务(任何一个参与者向协调者反馈了No响应,或者等待超时之后,协调者尚未收到所有参与者的反馈响应,就会中断事务)
1.发送回滚请求        协调者向所有参与者节点发出RoollBack请求.    
2.事务回滚        参与者接收到RoollBack请求后,会利用其在阶段一中记录的Undo信息来    
3.反馈事务回滚结果        参与者在完成事务回滚之后,向协调者发送ACK消息.    
4.中断事务        协调者收到所有参与者反馈的ACK消息后,完成事务中断.

二阶段提交协议的缺点 ：同步阻塞，单点问题，脑裂
   ●同步阻塞：（参与者互相等待！事务期间协调者参与者是锁住的）
        ==>各个参与者完成时间不一，必然存在某些参与者等待其他未完成参与者完成事务操作。在等待过程中无法执行其他任何操作。
  ●单点问题：（协调者宕机会阻塞参与者 不能提交也不能回滚！ ）
        ==>协调者占据主导地位
        ==>一旦协调者出出现问题，那么整个事务则无法完成，尤其是在阶段二中出现问题，各个参与者所锁定的资源将无法释放。
		导致其他业务不能操作
   ●脑裂导致数据不一致：（参与者未接收到协调者发送的commit）
        ==>如果分布式节点出现网络分区，某些参与者未收到commit提交命令。则出现部分参与者完成数据提交。
		未收到commit的命令的参与者则无法进行事务提交。整个分布式系统便出现了数据不一致性现象。


3pc 三阶段提交 Three-Phase Commit 
将二阶段提交协议“提交事务请求”过程一分为二，形成了CanCommit事务询问,PreCommit预备提交和do Commit真正提交三个阶段。
 阶段一: CanCommit    
1.事务询问    协调者向所有的参与者发送一个包含事务内容的canCommit请求,询问是否可以进行事务提交操作.    
2.各参与者向协调者反馈事务询问的响应    
参与者在接收到来自协调者的canCommit请求后,如果自身认为可以顺利执行事务,那么会反馈YES响应,并且进入预备状态,否则反馈No.
 阶段二:PreCommit在阶段二中,协调者会根据参与者的反馈情况来决定是否可以进行事务的PreCommit操作,
正常情况下.包含两种可能.
执行事务预提交    
1.执行预提交请求    协调者向所有的参与者发出preCommit的请求,并进入Prepared阶段.    
2.事务预提交    参与者接收到了preCommit请求后,会执行事务操作,并将Undo和Redo信息记录到事务日志中.    
3.各参与者向协调者反馈事务执行的响应    如果参与者成功执行了事务操作,那么就会反馈给协调者Ack响应,
同事等待最终的指令:提交(commit)或中止(abort)中断事务    
假如任何一个参与者向协调者反馈了No响应,或者在等待超时之后,协调者尚无法接收到所有参与者的反馈响应,那么就会中断事务.    
1.发送中断请求        协调者向所有参与者节点发出abort请求    
2.中断事务        无论是收到来自协调者的abort请求,或者是在等待请求过程中超时,参与者都会中断事务.
 阶段三:doCommit该阶段将进行真正的事务提交,也会存在两种可能情况.执行事务提交    
 1.发送提交请求        
 进入这一阶段,假设协调者处于正常工作的状态,并且它收到了来自所有参与者的ACK响应.
 那么就会从预提交转换到"提交"状态,并向所有的参与者发出doCommit请求.    
 2.事务提交        参与者接收到doCommit请求后.会正式执行事务提交操作,并在完成提交之后释放在整个事务执行期间所占用的资源.    
 3.反馈事务提交结果        参与者在完成事务提交之后,会向协调者发送ack消息.    
 4.完成事务        协调者接收到所有参与者反馈的ACK消息后,完成事务.中断事务进入到了这个阶段,假设协调者处于正常工作状态,
 任意有一个参与者向协调者反馈了no响应.或者超时之后协调者不能收到所有参与者的反馈响应,就会中断事务.        
 1.发送中断请求        协调者向所有的参与者节点发送abort请求.    
 2.事务回滚        参与者接收到abort请求之后,会利用其在阶段二中记录的Undol信息来执行事务回滚操作,
 并在完成事务回滚后释放所占用资源.    
 3.反馈事务回滚的结果.        参与者在完成事务回滚之后,向协调者发送ACK消息.    
 4.中断事务        协调者接收到所有参与者反馈的ACK消息后,中断事务.


三阶段提交协议的缺点 ：
CanCommit阶段解决参与者之间的互相等待 参与者不直接执行，
而是在 大概率 都可以执行的情况下 才进入预提交阶段执行 相对减少需要回滚的造成的参与者等待
加超时计时器解决协调者单点故障阻塞问题 
三阶段提交协议的缺点：
参与者收到preCommit消息之后,执行了事务返回ACK，但在第三阶段如果出现了网络分区,协调者和参与者无法正常进行网络通信.
那么在这种情况下,参与者超时事务回滚,其他正常的节点事务都提交了，这必然会导致数据出现不一致性。

可以在恢复时和协调者对比，利用redo undo日志，保证最终的一致性。

知道哪些分布式框架
Dubbo是一款高性能、轻量级的开源Java RPC框架，它提供了三大核心能力：
面向接口的远程方法调用，智能容错和负载均衡，以及服务自动注册和发现。
主要核心部件
Remoting: 网络通信框架，实现了 sync-over-async 和Logo request-response 消息机制.
RPC: 一个远程过程调用的抽象，支持负载均衡、容灾和集群功能
Registry: 服务目录框架用于服务的注册和服务事件发布和订阅





