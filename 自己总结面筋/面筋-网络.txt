HTTP/1.0 与 HTTP/1.1 的区别
1。HTTP/1.0仅支持HEAD、POST、GET、DELETE、PUT5种
2。HTTP/1.1 默认是持久连接:
“CONNECTION：KEEP-ALIVE”，建立一次TCP连接，进行多次Http通信，只要没明确断开连接就保持。
3。HTTP/1.1 支持管线化技术：
持久连接使得管线化成为可能：“并行发送多个请求”，不需要一个请求等待一个响应。
4。HTTP/1.1 支持虚拟主机：
虚拟主机：一台物理服务器对应多个域名
通常域名或者ip可以写在完整的url里，也可以放在“首部字段Host”里，
但是虚拟主机一个IP可能对应多个域名，必须在Host首部字段指定域名的url

HTTP/1.1 与 HTTP/2.0 的区别
1多路复用：
HTTP/1.1 试过用流水线(pipelining)或叫管线化, 但是效果并不理想
，浏览器客户端在同一时间针对同一域名的请求有一定数据限制，超过限制数目的请求会被阻塞。
HTTP2.0使用了多路复用的技术，“同一个连接并发处理多个请求，甚至可以在传输过程中将一个消息跟另外一个掺杂在一起”，
而且并发请求的数量比HTTP1.1大了好几个数量级。
2服务端推送
HTTP/2.0 在客户端请求一个资源时，会把“相关的资源（认为客户端需要的）一起发送”给客户端，客户端就不需要再次发起请求了。
例如客户端请求 index.html 页面，服务端就把 index.js 一起发给客户端。
3首部压缩
HTTP/1.1 的首部带有大量信息，而且每次都要重复发送。HTTP/2.0 要求通讯双方各自缓存一份首部字段表，从而避免了重复传输。
4二进制格式
HTTP/1.1 的解析是基于文本的，而 HTTP/2.0 采用二进制格式更高效。

CONNECT要求隧道协议连接:SSL,TSL把通信内容加密（注意：加密后通信内容仍可以通过抓包获取，只是无法破解）
http通过和SSL（Secure Socket layer安全套接层）或 TLS（Transport Layer Security安全传输层协议）组合使用，加密通信内容。
！！！TLS的前身是SSL


SSL位于http和tcp之间，
http+SSL=http+加密+认证=https
“SSL不仅提供加密处理”，
由于http不会对通信方身份认证，可能出现中间伪装的客户端、服务端，“SSL还提供证书证明客户端、服务器身份”，
由可信任的第三方颁发来解决“伪装问题”。
对称加密：加密解密用一个密钥
非对称加密：公钥、私钥（A向B发送数据，A用B公钥来“加密”，用A私钥“签名”；B收到，用A公钥“验证”，用B私钥“解密”。）

https认证过程？证书是什么？
首先服务端必须要配置一套数字证书，可以是自己制作或者CA证书。
区别就是自己颁发的证书需要客户端验证通过，才可以继续访问，而使用CA证书则不会弹出提示页面。
“这套证书包含一对公钥和私钥加上第三方机构用私钥签的名，以及颁发机构和过期时间等”。公钥给别人加密使用，私钥给自己解密使用。

如何确认第三方机构的权威？
第三方机构的“公钥已经事先植入浏览器”，并且存在一个信任链，
如果证书不受信任，会显示https warning，确认网站的真实性。

客户端发起HTTPS请求后，https握手过程（注意：在TCP的三次握手之后。由非对称加密也有对称加密）？
在此之前要进行https认证，即服务器要有证书。

1。建立服务器443端口连接（TCP）

2。SSL握手（证书，随机数，密钥）：
	“传送证书”，证书包含了被颁发机构签过名的服务端信息，过期时间等。
	“客户端解析证书”，由客户端的TLS来完成的，首先用第三方的公钥验证证书是否有效，比如颁发机构，过期时间等，如果发现异常，
则会弹出一个警告框，提示证书存在问题。如果证书没有问题，那么就生成一个随即值，然后用证书对该随机值进行加密。
	“传送加密信息”，这部分传送的是“用证书加密后的“！！！随机值”，目的就是让服务端得到这个随机值”，
服务端用私钥解密后，得到了客户端传过来的随机值(私钥)，以后客户端和服务端的通信就可以通过这个随机值来进行对称加密解密了。
所谓对称加密就是，加密解密用的同一个私钥。

3。服务端发送加密响应
	服务端把内容通过该值进行“对称加密”，传输加密后的信息。
4。客户端解密信息
	客户端用之前生成的随机值私钥解密服务段传过来的信息，获取解密后的内容。
5。关闭SSL

6。关闭TCP

HTTPS采用的加密方式：
在交换密钥阶段使用非对称加密方式，之后建立通信交换报文阶段则使用对称加密方式。
因为非对称加密慢但是可以避免伪装问题，也能避免随机值私钥的泄漏。



直接请求转发(Forward)
间接请求转发(Redirect)，重定向
对应到代码里，分别是RequestDispatcher类的forward()方法和HttpServletRequest类的sendRedirect()方法。
1.从地址栏显示来说
forward是服务器请求资源,“服务器直接访问目标地址的URL”,把那个URL的响应内容读取过来,然后“把这些内容再发给浏览器”.
浏览器根本不知道服务器发送的内容从哪里来的,所以它的地址栏还是“原来的地址”.（一次请求）
redirect是服务端根据逻辑,发送一个状态码,告诉“浏览器重新去请求那个地址”.所以地址栏显示的“是新的URL”.（两次请求）
2.从数据共享来说
forward:转发页面和转发到的页面可以“共享request里面的数据”.
redirect:不能共享数据.
3.从运用地方来说
forward:一般用于用户登陆的时候,根据角色“转发到相应的模块”.
redirect:一般用于用户注销登陆时返回主页面和“跳转到其它的网站等”.
间接转发方式，有时也叫重定向，它一般用于避免用户的非正常访问。例如：用户在没有登录的情况下访问后台资源，
Servlet可以将该HTTP请求重定向到登录页面，让用户登录以后再访问。在Servlet中，通过调用response对象的SendRedirect()方法，
告诉浏览器重定向访问指定的URL，
4.从效率来说
forward:高.
redirect:低.

DNS实现的机制
分布式的层次数据库模式以及缓存方法来解决集中式的单点故障问题（一台机器出问题就整体故障）
根据域名的分隔点构建树状层次结构。
https://blog.csdn.net/en_joker/article/details/81282067
DNS解析过程：
LDNS（本地：网络提供商）------依次去找下面这三类服务器----》
Root Server（根：划分.com.cn域名类别）、gTLD Server（主：划分域名服务提供商）、Name Server（记录映射关系，缓存失效时间）

第4步，如果LDNS（本地域名服务器）仍然没有命中，就直接到Root Server（根域名服务器）请求解析。
第5步，Root Server返回给LDNS一个所查询域的主域名服务器（gTLD Server）地址。gTLD是国际顶级域名服务器，如.com、.cn、.org等。
第6步，本地域名服务器（Local DNS Server）再向上一步返回的gTLD服务器发送请求。
第7步，接受请求的gTLD服务器查找并返回此域名对应的Name Server域名服务器的地址，这个Name Server通常就是你注册的域名服务器，
例如你在某个”域名服务提供商“申请的域名，那么这个域名解析任务就由这个域名提供商的服务器来完成。
第8步，Name Server域名服务器会查询存储的域名和IP的映射关系表，在正常情况下都根据域名得到目标IP记录，
连同一个TTL值（缓存失效时间）返回给DNS Server域名服务器。
第9步，返回该域名对应的IP和TTL值，Local DNS Server会缓存这个域名和IP的对应关系，缓存的时间由TTL值控制。
第10步，把解析的结果返回给用户，用户根据TTL值缓存在本地系统缓存中，域名解析过程结束。

点击网页链接访问过程？
浏览器通过域名找出其IP地址（
！浏览器缓存→hosts文件→Local DNS（互联网服务提供商如：电信）缓存→Local DNS请求根域名服务器（Root Server）解析。
前三步在客户端递归查询，最后一步在DNS服务器内部迭代查询。若修改hosts文件，可自己指定域名的IP，“绕过”DNS。）
浏览器和服务器建立连接（TCP三次握手）
（如果是https，先通过SSL认证和加密，再进行通信。）
浏览器向服务器发送请求
服务器接受到请求并返回响应
浏览器解析渲染页面
（如果是https，关闭SSL认证和加密）
断开连接（四次挥手）





TCP/IP协议簇以及五层、七层模型及各层协议
一。应用层：
邮箱使用的POP3，SMTP、远程登录使用的Telnet、获取IP地址的DHCP、域名解析的DNS、网页浏览的http协议

表示层：决定数据的展现（编码）形式，如同一部电影可以采样、量化、编码为RMVB、AVI，一张图片能够是JPEG、BMP、PNG等。

会话层：为两端通信实体建立连接（会话），中间有认证鉴权以及检查点记录（供会话意外中断的时候可以继续，类似断点续传）。

二。传输层TCP：可靠的（准确可靠的传送 3次握手 4次挥手 快速重传、滑动窗口、流量控制、拥塞控制、慢启动机制） 
字节流服务（http请求报文、报文段之间分割、重组 序列号）

    序列号seq：用来标记报文段的顺序，TCP把连接中发送的所有数据字节都编上一个序号，
	序列号seq就是这个“报文段中的第一个字节”的数据编号。

    确认号ack：“期待收到”对方下一个报文段的序列号；
	因此当前报文段“最后一个字节的编号+1”即为确认号。

    确认ACK：仅当ACK=1时，确认号字段才有效。ACK=0时，确认号无效

    同步SYN：连接建立时用于同步序号。当SYN=1，ACK=0时表示：这是一个连接请求报文段。
若同意连接，则在响应报文段中使得SYN=1，ACK=1。因此，SYN=1表示这是一个连接请求，或连接接受报文。
SYN这个标志位只有在TCP建产连接时才会被置1，握手完成后SYN标志位被置0。

    终止FIN：用来释放一个连接。FIN=1表示：此报文段的发送方的数据已经发送完毕，并要求释放运输连接

    PS：ACK、SYN和FIN这些大写的单词表示标志位，其值要么是1，要么是0；ack、seq小写的单词表示序号。
------------------------------
https://blog.csdn.net/qq_38950316/article/details/81087809
第一次握手：建立连接时，客户端发送SYN包（seq=j）到服务器，并进入SYN_SENT状态，等待服务器确认；
第二次握手：服务器收到SYN包，发送SYN（seq=k）+ACK（ack=j+1）包，此时服务器进入SYN_RECV状态；
第三次握手：客户端收到服务器的SYN+ACK包，向服务器发送确认包ACK(ack=k+1），此包发送完毕，客户端和服务器进入ESTABLISHED。


为什么3次握手？
（确认双方的接收、发送都没问题需要3次；
重发机制加网络原因，有后到达的SYN，服务器之间回复ACK建立连接，浪费资源；）

--------------------- 
四次挥手：
1  Client发送一个fin，用来关闭Client到server的数据传输，Client进入fin_wait。 
2  server接到fin，发送ack给Client，自己进入close_wait(等待关闭状态)。 
3  server发送一个fin，用来关闭server到Client的数据传输。
4  Client接收到fin，发送ack给Server，自己进入Time_wait状态，server接收到ack进入关闭状态，
Client等待2MSL(Maxmum segment lifetime),它是任何报文在网络丢弃前在网络内的最长时间，过了这个时间，Client就自动关闭了。

1）客户端进程发送FIN=1，其序列号为seq=u（等于前面已经传送过来的数据的最后一个字节的序号加1），
此时，客户端进入FIN-WAIT-1（终止等待1）状态。 TCP规定，FIN报文段即使不携带数据，也要消耗一个序号。
2）服务器收到连接释放报文，发出确认报文，ACK=1，ack=u+1，并且带上自己的序列号seq=v，
此时，服务端就进入了CLOSE-WAIT（关闭等待）状态。
TCP服务器通知高层的应用进程，客户端向服务器的方向就释放了，这时候处于“半关闭”状态，即客户端已经没有数据要发送了，
但是服务器若发送数据，客户端依然要接受。这个状态还要持续一段时间，也就是整个CLOSE-WAIT状态持续的时间。
客户端收到服务器的确认请求后，此时，客户端就进入FIN-WAIT-2（终止等待2）状态，
等待服务器发送连接释放报文（在这之前还需要接受服务器发送的最后的数据）。
3）服务器将最后的数据发送完毕后，就向客户端发送连接释放报文，FIN=1，ack=u+1，
由于在半关闭状态，服务器很可能又发送了一些数据，假定此时的序列号为seq=w，
此时，服务器就进入了LAST-ACK（最后确认）状态，等待客户端的确认。
4）客户端收到服务器的连接释放报文后，必须发出确认，ACK=1，ack=w+1，而自己的序列号是seq=u+1，
此时，客户端就进入了TIME-WAIT（时间等待）状态。注意此时TCP连接还没有释放，
必须经过2MSL（最长报文段寿命）的时间后，当客户端撤销相应的TCB后，才进入CLOSED状态。
服务器只要收到了客户端发出的确认，立即进入CLOSED状态。
！！！“可以看到，服务器结束TCP连接的时间要比客户端早一些。”客户端主动关闭进入TIME-WAIT，服务端被动关闭进入CLOSE-WAIT

为什么4次挥手？？？
TCP是全双工模式，接收方接收到FIN意味着没有数据再发来，但是还可以继续发送数据。
即在CLOSE-WAIT阶段，服务器仍可以继续向客户端发送数据，处于半关闭状态。

！！！为什么挥手最后要等待2MSL(Maxmum segment lifetime“最长报文段寿命”)才中断？？？
1.2MSL就可以让本连接持续的时间内所产生的所有报文段都从网络中消失，确保下一个新的连接不会出现旧连接的报文段。
2.为了保证客户端发送的最后一个ACK报文能够到达服务端。如果服务端没有收到，则会重传自己的FIN+ACK报文段给客户端，
因此客户端会在2MSL时间内收到服务端的报文段，接着客户端重新发送ACK一次，重新启动2MSL“计时器”。
进入TIME_WAIT状态，如果Server端没有收到ACK则可以重传。“，Server端收到ACK后，"就知道可以断开连接了"。
相反，客户端端等待了2MSL后依然没有收到回复，则证明Server端已正常关闭，


如果已经建立了连接，但是客户端突然出现故障了怎么办？（先计时，再探测，无反应主动关闭连接）
TCP设有一个超时计时器，显然，客户端如果出现故障，服务器不能一直等下去，白白浪费资源。
“服务器每收到一次客户端的请求后都会重新复位这个计时器”，时间通常是设置为2小时，
若两小时还没有收到客户端的任何数据，“服务器就会发送一个探测报文段”，以后每隔75秒钟发送一次。
若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。
--------------------- 

和udp区别？
1、TCP是面向连接的（传输数据之前要先3次握手建立连接），UDP是无连接的
2、TCP提供“可靠”的服务（通过TCP传输的数据无差错，不丢失，不重复，通过报文头的序列号且按序到达：
Tcp通过校验和，重传控制，序号标识，滑动窗口、确认应答实现可靠传输。）
UDP提供简单的不可靠的传输。
3、UDP实时性比TCP高，多用于视频、音频即时通讯（实时性要求高）。
4、TCP连接只能是点到点的，UDP支持一对一，一对多和多对多的交互通信。
7、TCP拥有流量控制及拥塞控制的机制。
8、TCP基于字节流，可能粘包，而UDP基于数据报，不会。

应用：Http为了保证可靠性，基于tcp。
打电话场景，tcp的丢失重发会影响通话”流畅性“，udp数据丢失影响的是小部分通话，不会大幅度延迟到达！

“自动重传请求”(Automatic Repeat-reQuest,ARQ)
！停止等待ARQ
停等ARQ协议是停等流控技术和请求重发技术的组合。发送方在发出一个帧后，如若收到ACK应答信号，则继续发出下一帧；
如收到NAK信号，则重发该帧；如果一定时间间隔未收到应答信号也须重发。
！连续ARQ
“连续ARQ协议是滑动窗口技术和请求重发技术的组合”。
接收方有一个固定大小的窗口，接收方在收到一个帧以前不会移动窗口，发送方可以发送连续的帧而形成流动，因此称为连续ARQ协议。
连续ARQ协议根据出错帧和丢失帧分为选择重发ARQ协议和后退N帧ARQ协议。
重发ARQ协议为只发出错帧，后退N帧ARQ协议为从丢失处重发帧以后的帧


三。路由层，IP地址可变、mac（网卡）地址不变
ARP协议：“地址解析协议”，即ARP（Address Resolution Protocol），是根据IP地址获取物理地址。
以“广播方式！”发送一个ARP请求报文。
ARP请求报文包含发送端IP地址和发送端MAC地址，目标IP地址和目标MAC地址（“还不知道，设置为全0的MAC地址”）。
由于ARP请求报文以广播方式发送，该网段上的所有主机都可以接收到该请求，“但只有被请求的主机会对该请求进行处理”。
收到返回消息后将该IP地址和物理地址存入本机ARP缓存中并保留一定时间，下次请求时直接查询ARP缓存以节约资源。


四。数据链路层：
根据端口与MAC地址，做分组（VLAN）隔离、端口安全、访问控制。
（MAC地址在这一层）处理VLAN内的数据帧转发，跨VLAN间的访问，需要上升到网络层。

五。物理层：
将数据最终编码为用0、1标识的比特流，然后传输。（例如将题主头像的图片，变为一串01100111100这样的数字来表示）。


TCP/IP识别一个通信的5大要素：源、目标端口号，源、目标ip地址、协议。

！！！各层的报文格式？
封装数据，从上往下，每一层加上该层首部
HTTP：请求/响应的报文

TCP：
源、目标端口号，顺序号（SEQ），确认号（ACK），窗口大小，TCP校验和字段等

IP：
版本（ruIPv4 IPv6），源IP地址、目标IP地址，协议（TCP、UDP），长度字段等

------------------------------------------------------------------------------
nagle算法和TCP粘包问题，怎么处理？
nagle算法用于处理小报文段的发送问题，可以提高网络利用率，但会带来延迟。
nagle算法的核心思想是允许“网络中最多只能有一个小报文段被发送”，而待发送的其它小报文段会被重新组合一个”较大的”报文段，
只有等收到上一个小报文段的确认应答后，或者组合的报文段达到最大段长度（MSS）时再发送！

！！！粘包原因（首先发送方、接收方多个包被粘一起（nagle算法、连续发送或连续接收加上操作系统有缓存机制），
然后接收方不知道每次取出多少）
1.nagle算法组合了多个包 或者 连续发送连续接收多个包的时候
2发生黏包主要是因为接收者不知道发送者发送内容的长度（期待的下一个序列号只定义了起始位），
因为tcp协议是根据数据流的，计算机操作系统有缓存机制，所以当连续发送或连续接收多个包 或者nagle算法组合了多个包的时候，
而接收方不知道消息之间的界限，不知道一次性提取多少字节的数据，取出部分数据，导致第一个报文段和第二个报文段可能粘在一起！

发送端需要等缓冲区满才发送出去，造成粘包（发送数据时间间隔很短，数据了很小，会当做一个包发出去，产生粘包）
接收方不及时接收缓冲区的包，造成多个包接收（发送方连续发送，接收方每次取出一部分，并且不知道界限，
下次再收的时候还是从缓冲区拿上次遗留的数据，产生粘包） 

解决方案（
解决粘包的方法就是围绕，如何让发送端在发送数据前，“把自己将要发送的字节流总大小让接收端知晓（固定长度 或 变长封装在首部）”，
然后接收端来一个死循环接收完所有数据）
1、发送端封装数据，给每个数据包添加包首部，首部中应该至少包含数据包的长度，这样接收端在接收到数据后，通过读取包首部的长度字段，
便知道每一个数据包的实际长度了。
2、发送端将每个数据包封装为固定长度（不够的可以通过补0填充），接收端每次从接收缓冲区中读取固定长度就自然而然的把数据包拆分开。

！UDP是否会发生粘包或拆包的现象呢？答案是不会。
UDP是“基于报文发送”的，从UDP的帧结构可以看出，“在UDP首部采用了16bit来指示UDP数据报文的长度，
因此在应用层能很好的将不同的数据报文区分开”，从而避免粘包和拆包的问题。
而TCP是“基于字节流”的，虽然应用层和TCP传输层之间的数据交互是大小不等的数据块，但是TCP把这些数据块仅仅看成一连串“无结构的字节流，
没有边界”；另外从TCP的帧结构也可以看出，在TCP的首部没有表示数据长度的字段，
基于上面两点，在使用TCP传输数据时，才有粘包或者拆包现象发生的可能。

关键词：nagel算法组合小报文段，连续发送连续接收，操作系统缓存，
基于字节流，接收端不知道多个包的界限。 固定长度 或 变长封装在首部
------------------------------------------------------------------------------


无差错怎么校验的？TCP如何检测数据报是否损伤？
TCP校验和是一个端到端的校验和，由发送端计算，然后由接收端验证。其目的是为了发现TCP首部和数据在发送端到
接收端之间发生的任何改动。如果接收方检测到校验和有差错，则TCP段会被直接丢弃。

TCP校验和覆盖TCP首部和TCP数据，计算校验和时，都要加上一个“伪首部”，如果计算结果为全1，说明数据没有收到损伤。
把需要进行校验的“字串”加起来，把这“相加的结果取反”当做
“校验和” （Checksum）， 比如，相加的结果是0101，那么“校验和”就
是1010，验证的时候呢，如果0101+1010 = 1111就是正确的。



由于不同协议，tcp/udp同一个端口号不互相影响
常见端口，一个进程的端口上限？
1.HTTP协议代理服务器常用端口号：80/8080/3128/8081/9098（默认是80）
HTTPS443
2.SOCKS代理协议服务器常用端口号：1080
3.FTP（文件传输）协议代理服务器常用端口号：21
4.Telnet（远程登录）协议代理服务器常用端口号：23



http请求报文，响应报文结构
请求报文
请求行（方法 url http协议） 首部字段（通用首部、请求首部、实体首部） 空行 请求实体
响应报文（协议 状态码 状态码解释）
响应行 首部字段（通用首部、响应首部、实体首部） 空行 响应实体

首部字段为了客户端和浏览器传递额外信息，如报文类型和大小、编码解码、使用的语言等
常见的首部字段如下
通用首部字段：
Cache-Control  控制缓存
Connection 连接管理
via 代理服务器的相关信息
Date 创建报文的日期

请求首部字段：
Accept 客户端或者代理能够处理的媒体类型
Accept-Encoding 优先可处理的编码格式
Accept-Language 优先可处理的自然语言
Accept-Charset 优先可以处理的字符集
Host 请求资源所在服务器
User-Agent 客户端程序信息
Range 实体的字节范围请求

响应首部字段：
Server 服务器的信息
Location 令客户端重定向的URI
Retry-After 和状态码503 一起使用的首部字段，表示下次请求服务器的时间
Accept-Ranges 能接受的字节范围

实体首部字段：
Allow 资源可支持http请求的方法
Content-Language 实体的资源语言
Content-Encoding 实体的编码格式
Content-Length 实体的大小（字节）
Content-Type 实体媒体类型


http支持的常见方法HEAD、POST、GET、DELETE、PUT、OPTIONS、CONNECT、TRACE
DELETE、PUT不安全
1、OPTIONS
返回服务器针对特定资源所支持的HTTP请求方法
2、HEAD
向服务器索与GET请求相一致的响应，只不过响应体将不会被返回。
这一方法可以再不必传输整个响应内容的情况下，就可以获取包含在响应消息头中的信息。
3、GET
向特定的资源发出请求。它本质就是发送一个请求来取得服务器上的某一资源。get请求无消息体。
4、POST
向指定资源提交数据进行处理请求（例如提交表单或者上传文件）。“数据被包含在请求体中”。
POST请求可能会导致新的资源的建立和/或已有资源的修改。
5、PUT
向指定资源位置上传其最新内容
6、DELETE
请求服务器删除Request-URL所标识的资源
7、TRACE
回显服务器收到的请求，主要用于测试或诊断
8、CONNECT
使用隧道方式加密通信


POST、GET区别？
get将数据放在url地址中，无消息体；post将数据放在消息体中
GET不安全，因为参数直接暴露在URL上，所以不能用来传递敏感信息
GET提交的数据量最多只能有1024字节，受到浏览器的限制，而POST则没有此限制
GET请求只能进行url编码，只支持只接受ASCII字符，而POST支持多种编码方式
get是幂等的，post不是

幂等和不幂等的方法？
POST不满足


常见响应码和解释？
1xx正在处理、2xx成功、3xx重定向、4xx客户端错误、5xx服务器错误
200 ok成功
204 no content请求处理成功但不需要资源返回（响应报文实体为空）
206 partial content返回部分资源（需要Content-range指定范围）

301 moved permanently 永久性重定向（资源的url已经更新）
302 found 临时性重定向（资源临时分配了新的url）
303 see other 功能同302并且客户端应该用GET方法访问新的url
304 not modified 客户端发送附带条件的请求，服务端没找到。（与重定向无关）

400 bad request 请求报文存在语法错误
401 unauthorized 需要进行HTTP认证或者需要登陆的（第一次弹出认证页面，第二次再弹出表示认证失败）
403 forbidden 请求资源被服务器拒绝（如未授权的IP地址）
404 not found 服务器上无法找到请求的资源
405 （方法禁用） 禁用请求中指定的方法

500 internal server error 服务器出现错误（程序bug或临时故障）
502 （错误网关） 只有代理服务器或网关会发送此响应代码，表明从上游服务器收到无效响应。
503 service unavailable 服务器超负载或者停机维护（响应字段加上Try-After）
504 （网关超时） 只有代理服务器或网关会发送此响应代码，表明没有及时从上游服务器收到请求。

http无状态的理解？
http协议“本身”不对请求和响应之间的通信状态保存，是面向资源的。

https://blog.csdn.net/weixin_41910244/article/details/80287527
Session会话，会话是指我们访问网站的一个周期（在这个站点点击多个超链接查看各个网页，然后关闭浏览器，整个过程称之为一个会话。）
！！！会话跟踪，理论上，一个用户的所有请求操作都应该属于同一个会话。而另一个用户的所有请求操作则应该属于另一个会话。
引入session cookie技术
-----------------------------一个会话------------------------------------------------------
“客户端第一次请求”，服务器生成session（包含sessionID和“对应的用户信息、用户操作记录在服务器上”），
同时服务端生成cookie（！包含sessionId），
在响应报文里加上SET-COOKIE字段，通知客户端保存cookie（包含sessionId），
“客户端下次请求”自动在请求报文中加上cookie，服务端通过检查sessionID获取用户信息和记录。
-----------------------------一个会话------------------------------------------------------
区别：Cookie机制是通过检查客户身上的“通行证”来确定客户身份的话，那么Session机制就是通过检查服务器上的“客户明细表”来确认客户身份。
cookie存储的数量和字符数量都有限制，只能存储几十个，不超4096左右个字符。
cookie存储在用户浏览器里也不安全，打开浏览器控制台，任何人都能直接查看。
cookie只存储字符串信息。

session保存在服务器端比较安全，如果Session内容过于复杂，对服务器的存储压力很大。
session可以存储对象。

如何防止session引起内存溢出？
1尽量精简session的信息
2Session生成后，只要用户继续访问，服务器就会更新Session的“最后访问时间”，并维护该Session。
为防止内存溢出，服务器会把超过“超时时间”的失效Session从内存删除。

解决禁用cookie？？？
由于cookie可以被人为的禁止，必须有其它的机制以便在cookie被禁止时“仍然能够把session id传递回服务器”，
经常采用的一种技术叫做“URL重写”，就是附加session id到url，一种是作为URL路径的附加信息，另一种是作为查询字符串附加在URL后面。



https://www.cnblogs.com/ranyonsue/p/8918908.html
缓存命中率：直接从缓存中就可以得到数据的请求数与所有请求数的比率。
！！！Web 缓存大致可以分为：！浏览器缓存、！服务器端缓存（代理服务器缓存）、！数据库缓存。
浏览器缓存也包含很多内容： HTTP 缓存、cookie、indexDB、localstorage 等等
HTTP缓存机制：
用 HTTP 头信息控制缓存Cache-Control。
Expires用来指定资源到期的时间，是服务器端的具体的时间点。
Cache-Control是一个相对时间，都是与客户端时间比较，所以服务器与客户端时间偏差也不会导致问题
，因此cache-control的优先级更高。


https://www.jianshu.com/p/9c95db596df5
！！！强缓存就是给资源设置个过期时间，客户端每次请求资源时都会看是否过期；只有在过期才会去询问服务器。
cache-control: max-age=xxxx，public
客户端和代理服务器都可以缓存该资源；
客户端在xxx秒的有效期内，如果有请求该资源的需求的话就直接读取缓存,statu code:200 ，如果用户做了刷新操作，就向服务器发起http请求
cache-control: max-age=xxxx，private
只让客户端可以缓存该资源；代理服务器不缓存
客户端在xxx秒内直接读取缓存,statu code:200
cache-control: max-age=xxxx，immutable
客户端在xxx秒的有效期内，如果有请求该资源的需求的话就直接读取缓存,statu code:200 ，即使用户做了刷新操作，也不向服务器发起http请求
cache-control: no-cache
跳过设置强缓存，但是不妨碍设置协商缓存；一般如果你做了强缓存，只有在强缓存失效了才走协商缓存的，
设置了no-cache就不会走强缓存了，每次请求都回询问服务端。
cache-control: no-store
不缓存，这个会让客户端、服务器都不缓存，也就没有所谓的强缓存、协商缓存了。

！！！设置协商缓存？
last-modified：文件的修改时间，精确到秒
（相当于是否改变的校验码）
但是有时候通过最后修改时间来判断资源是否修改还是不太准确
（！！！“Last-Modified标注的最后修改只能精确到秒级，资源变化了最后修改时间也可以一致”）。
并且如果某些文件会被定期生成，当有时内容并没有任何变化，但Last-Modified却改变了，导致文件没法使用缓存。
于是出现了ETag/If-None-Match。
etag：每个文件有一个，改动文件了就变了，就是个文件hash，每个文件唯一，就像用webpack打包的时候，每个资源都会有这个东西，
如： app.js打包后变为 app.c20abbde.js，加个唯一hash，也是为了解决缓存问题。
ETag可以保证每一个资源是唯一的，资源变化都会导致ETag变化*。ETag值的变更则说明资源状态已经被修改。
服务器根据浏览器上发送的If-None-Match值来判断是否命中缓存。



浏览器缓存分为“强缓存和协商缓存”，浏览器加载一个页面的简单流程如下：
浏览器先根据这个资源的http头信息来判断是否命中强缓存。如果命中则直接加载缓存中的资源，并不会将请求发送到服务器。
如果未命中强缓存，则浏览器会将资源加载请求发送到服务器。
服务器来判断浏览器本地缓存是否失效（
浏览器第一次请求一个资源的时候，服务器返回的header中会加上Last-Modify，Last-modify是一个时间标识该资源的最后修改时间
当浏览器再次请求该资源时，发送的请求头中会包含If-Modify-Since，该值为缓存之前返回的Last-Modify。
服务器收到If-Modify-Since后，根据资源的最后修改时间判断是否命中缓存）。
若可以使用，则服务器并不会返回资源信息，浏览器继续从缓存加载资源。
如果未命中协商缓存，则服务器会将完整的资源返回给浏览器，浏览器加载新资源，并更新缓存。

发请求-->看资源是否过期-->过期-->请求服务器-->服务器对比资源是否真的过期-->没过期-->返回304状态码-->客户端用缓存的老资源。
发请求-->看资源是否过期-->过期-->请求服务器-->服务器对比资源是否真的过期-->过期-->返回200状态码-->客户端如第一次接收该资源一样，
记下它的cache-control中的max-age、etag、last-modified等。




代理和网关区别？
代理是多个使用使用相同协议的端点，网关是多个使用不同协议的端点。


socket，tcp或者udp的api，位于其上层


！！！TCP可靠性的理解
？？？提高可靠性（”无差错、不丢失、不重复、按序到达“理解）：
无差错：通过校验和保证，丢弃损伤包
不丢失：如果”一定时间“没收到确认应答（ACK），发送端认为丢包（但实际不一定数据丢包，可能ACK丢包），通过超时重传、快速重传保证
不重复：根据序列号判断丢弃重复的包
按序到达：顺序控制（报文切割成报文段，
第一个字节即序列号，发送会附上序列号、接收后表明自己”期待的“下一个序列号，并对重复的序列号丢弃）

！重发超时如何确定？
考虑往返时间和网络偏差，”保证确认应答一定能在这个时间内返回“。

MSS（maximum segment size最大报文段长度），在三次握手时双方确认，选择一个较小值使用。


？？？提高网络利用率：滑动窗口（发送端连续发送多个数据段）、流量控制（动态匹配接收端接收能力，零窗口处理）
、拥塞控制（考虑整个网络情况，起始短时间的大量报文段容易造成拥塞，主要有四个算法：慢启动、拥塞避免、快速重传和快速恢复。）

滑动窗口意义和含义？当每个报文段收到一个确认应答后才能发送下一个段，包的往返时间越长，吞吐量越差，
窗口大小就是”无需等待确认应答“可以继续发送段的最大数量。（
顺序地将多个段同时发送，！注意：仍然是一个段有一个确认应答，但可以连续发送！
还有好处是前面丢失的确认应答可以通过后面的确认应答确认）

根据滑动窗口将段区分：包含已发送已确认（可以清除缓存）；已发送未确认、未发送（保留缓存）

”快速“重传快在哪里？（区别超时重传）
滑动窗口下，当报文段丢失，期待序列号的确认应答将被重复返回，发送端如果3次收到同一个确认应答，
不必继续等待设置的重传计时器到期，立即重传。

流量控制：
发送端根据接收端告知的可接收数据大小，动态改变滑动窗口的大小，避免超出接收端负载无法处理，白白浪费网络资源。

！！！接收端缓冲区满了怎么办、如何流量控制出现的死锁（零窗口通知、窗口更新通知、窗口探测计时器）？
此时接收端会告知发送端缓冲区已满（”零窗口通知“），发送端停止发送数据。
等接收端缓冲区有空余，发”窗口更新通知“给发送端，但如果这个报文丢失，出现A等待B的通知||B等待A发送数据的死锁状态。
为了处理这种问题，TCP引入了”窗口探测“，当A收到对方的零窗口通知时，就启用该”计时器“，时间到则发送一个1字节的探测报文，
对方会在此时回应自身的接收窗口大小，如果结果仍为0，则重设持续计时器，继续等待。

！！！拥塞控制：主要有四个算法：慢启动（通信开始或者超时重传，收到ACK+=1）、拥塞避免（设定”慢启动阈值“避免窗口指数级增长）、
快速重传（3个连续相同ACK时不等超时重传）和快速恢复（快速重传后不再进入慢启动环节，直接进入拥塞避免）。

”通信开始时或者发生超时重传“，通过慢启动算法控制发送数据量。
拥塞窗口为1个报文段，之后每收到一个确认应答（会递增），拥塞窗口值加一，
并比较拥塞窗口和接收端的窗口大小，”取小的窗口“，发送比其还少的报文段。

！考虑每次往返，确认应答增加导致拥塞窗口增大，拥塞窗口增大紧接着又导致确认应答增加（正向激励的过程），
导致拥塞窗口以1、2、4等”指数增长“，设定”慢启动阈值“，当超过，减缓拥塞窗口的放大趋势。




